{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Understanding_CNNs.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9mZKShJHScnt"
      },
      "source": [
        "# Comprendre les CNN et leurs paramètres\n",
        "\n",
        "Un réseau de neurones convolutifs (CNN) est un réseau d'auto-apprentissage qui classe les images de manière similaire à la façon dont notre cerveau humain apprend, en observant des images de différentes classes. CNNs apprend le contenu d'une image en appliquant un filtrage d'image et en traitant les méthodes de différentes tailles de filtres, quantités et opérations non linéaires. Ces filtres et opérations sont appliqués sur de nombreuses couches de sorte que les dimensions spatiales de chaque couche suivante diminuent et que leurs profondeurs augmentent au cours du processus de transformation de l'image.\n",
        "\n",
        "Pour chaque application de filtrage, la profondeur du contenu appris augmente. Cela commence par la détection des contours, suivie de la reconnaissance des formes, puis d'une collection de formes appelées caractéristiques, et ainsi de suite. Ceci est analogue au cerveau humain en ce qui concerne la façon dont nous comprenons l'information. Par exemple.\n",
        "\n",
        "La méthode de filtrage et de traitement des images de CNN consiste à effectuer diverses opérations, toutes effectuées à l'aide des éléments suivants :\n",
        "\n",
        "* Convolution (Conv2D)\n",
        "* Convolution over volume – 3 x 3 filter\n",
        "* Convolution over volume – 1 x 1 filter\n",
        "* Pooling\n",
        "* Padding\n",
        "* Stride\n",
        "* Activation\n",
        "* Fully connected layer\n",
        "* Regularization\n",
        "* Dropout\n",
        "* Internal covariance shift and batch normalization\n",
        "* Softmax\n",
        "\n",
        "Voyons comment fonctionne chaque composant\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqB6eYffW_eH"
      },
      "source": [
        "## Convolution\n",
        "\n",
        "La couche de convolution est le bloc de construction le plus important d’un CNN. Dans la première couche de convolution, les neurones ne sont pas connectés à chaque pixel de l’image d’entrée, mais uniquement aux pixels dans leurs champs récepteurs. À leur tour, les neurones de la deuxième couche de convolution sont chacun connectés uni-quement aux neurones situés à l’intérieur d’un petit rectangle de la première couche. Cette architecture permet au réseau de se focaliser sur des caractéristiques de bas niveau dans la première couche cachée, puis de les assembler en caractéristiques de plus haut niveau dans la couche cachée suivante, etc. Cette structure hiérarchique est récurrente dans les images réelles et c’est l’une des raisons des bons résultats des CNN pour la reconnaissance d’images.\n",
        "\n",
        "Un neurone situé en ligne i et colonne j d’une couche donnée est connecté aux sorties des neurones de la couche précédente situés aux lignes i à i + fh − 1 et aux colonnes j à j + fw − 1, où fh et fw sont la hauteur et la largeur du champ récepteur(filter). Pour qu’une couche ait les mêmes hauteur et largeur que la couche précédente.\n",
        "\n",
        "la convolution consiste à multiplier une section de l'image avec un noyau (filtre) pour produire une sortie. L'opération de convolution est réalisée en faisant glisser le noyau sur l'image d'entrée. À chaque emplacement, une multiplication par élément par élément est effectuée, suivie d'une somme cumulative sur la plage de multiplication.\n",
        "\n",
        "<img src='http://learn-neural-networks.com/wp-content/uploads/2018/10/conv2-300x134.jpg' width=700px>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GRMZ4aKQd2cG"
      },
      "source": [
        "## Convolution sur IMAGE RGB – filtre 3 x 3\n",
        "\n",
        "Une image RGB peut être considérée en trois dimensions. Elle est composée de trois images en deux dimensions, une pour chaque canal. Chaque sous-image est une couche de profondeur (donnant donc une image globale de dimensions largeur*hauteur*profondeur : 3 dimensions. Comme l’image à laquelle nous appliquions le kernel était en deux dimensions, notre kernel l’était lui aussi\n",
        "\n",
        "Pour pouvoir appliquer un kernel(filtre) sur une image RGB, nous avons besoin d’un kernel pour chaque canal pour les traiter indépendamment. Nous avons donc trois kernels pour une image en couleurs. Plutôt que de les voir comme trois kernels distincts, nous pouvons dire qu’ils ne forment qu’un seul kernel, mais en trois dimensions. Il reste toujours associé à une seule caractéristique.\n",
        "Chaque couche de profondeur du kernel va faire son produit scalaire avec chaque canal de l’image, et l’opération va toujours se passer de la même manière en faisant la somme des produits terme à terme (y compris entre les sous-kernels). Il en ressort pour chaque application de l’opération une seule valeur, nous faisant donc obtenir en sortie une carte de caractéristique avec une seule couche en profondeur, donc en deux dimensions.\n",
        "\n",
        "\n",
        "\n",
        "<img src='https://www.researchgate.net/profile/Santhiya-Rajan/post/How-will-channels-RGB-effect-convolutional-neural-network/attachment/5c67b72d3843b0544e664e12/AS%3A726829115666434%401550300973344/image/cnn_1.gif' width=700px>\n",
        "\n",
        "L’objectif est toujours le même : que le kernel (donc ses sous-kernels) ressemble le plus possible à la caractéristique que nous souhaitons mettre en valeur pour que le résultat du produit scalaire des deux soit maximal.\n",
        "\n",
        "\n",
        "En général, dans une couche de convolution, il existe de nombreux filtres effectuant différents types de détection de contour.\n",
        "\n",
        "Par exemple 32 filtres de 3 x 3 peuvent être exprimés dans TensorFlow sous la forme. tf.keras.layers.Conv2D(32,(3,3))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7GUKRW47ccJi"
      },
      "source": [
        "## Pooling\n",
        "\n",
        "Le Pooling est l'opération suivante après la convolution. Il est utilisé pour réduire la dimensionnalité et la taille de la carte des caractéristiques (largeur et hauteur) sans modifier la profondeur. Le nombre de paramètres pour le Pooming est zéro.Les deux types de pooling les plus populaires sont les suivants:\n",
        "\n",
        "* Max pooling\n",
        "* Average pooling\n",
        "\n",
        "Dans max Pooling, nous glissons la fenêtre sur la carte des caractéristiques et prenons la valeur maximale de la fenêtre, tandis qu'avec pooling moyen, nous prenons la valeur moyenne dans la fenêtre. La figure suivante montre les opérations de pooling max et moyenne utilisées sur une image 4 x 4\n",
        "\n",
        "<img src='https://www.researchgate.net/profile/Zenghui-Wang-6/publication/317496930/figure/fig1/AS:551445004066816@1508486142257/Average-versus-max-pooling.png' width=500px>\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ucxIrXJq3pai"
      },
      "source": [
        "## Padding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxu8WDtL5KH8"
      },
      "source": [
        "Padding est utilisé pour préserver la taille de la carte des caractéristiques. Avec la convolution, deux problèmes peuvent survenir, et le Padding résout les deux:\n",
        "* La taille de la carte des caractéristiques diminue à chaque opération de convolution. Par exemple, dans la figure précédent, une carte de caractéristiques 5 x 5 se réduit à 3 x 3 en raison de la convolution.\n",
        "\n",
        "*Les informations sur le bord sont perdues car le pixel sur le bord n'est modifié qu'une seule fois, tandis que le pixel au milieu est modifié plusieurs fois par de nombreuses opérations de convolution.\n",
        "\n",
        "<img src='https://files.speakerdeck.com/presentations/86260627cf1e41e8876e2a0e581c4670/slide_10.jpg' width=500px>\n",
        "\n",
        "Notez comment le Padding conserve la dimension afin que la sortie soit de la même taille que l'entrée"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tqma7C-K8-yd"
      },
      "source": [
        "## Stride\n",
        "\n",
        "Normalement, dans une convolution, nous déplaçons le noyau d'un pas, appliquons une convolution à ce pas, et ainsi de suite. Le stride nous permet de sauter une étape. Nous allons jeter un coup d'oeil.\n",
        "\n",
        "* Lorsque Stride = 1, nous appliquons la convolution normale sans sauter\n",
        "* Lorsque Stride = 2, nous sautons une étape. Cela réduit la taille de l'image de 6 x 6 à 2 x 2 (voir la figure suivante suivante)\n",
        "<img src='https://indoml.files.wordpress.com/2018/03/stride.png?w=736' width=600px>\n",
        "\n",
        "Ici, chaque fenêtre 3 x 3 affiche les résultats du saut d'une étape. Le résultat d'une Stride est de réduire la dimension puisque nous sautons les emplacements potentiels x, y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZLdib0d_EBE"
      },
      "source": [
        "## Activation\n",
        "\n",
        "La couche d'activation ajoute de la non-linéarité au réseau de neurones. Ceci est essentiel car les images et les caractéristiques d'une image sont des problèmes hautement non linéaires, et la plupart des autres fonctions au sein des CNN (Conv2D, pooling, couches entièrement connectées, etc.) ne génèrent que des transformations linéaires. La fonction d'activation génère la non-linéarité tout en mappant les valeurs d'entrée à ses plages. Sans la fonction d'activation, quel que soit le nombre de couches ajoutées, le résultat final sera toujours linéaire.\n",
        "\n",
        "De nombreux types de fonctions d'activation sont utilisés, mais les plus courantes sont les suivantes :\n",
        "\n",
        "* Sigmoid\n",
        "* Tanh\n",
        "* ReLU\n",
        "\n",
        "Les fonctions d'activation précédentes peuvent être vues dans le graphique suivant:\n",
        "\n",
        "<img src='https://www.arabicprogrammer.com/images/974/d43415b88a3e9cbc566c1ad341b18bd6.JPEG' width=500px>\n",
        "\n",
        "Chacune des fonctions d'activation présente un comportement non linéaire.\n",
        "\n",
        "La fonction d'activation ReLU présente les avantages suivants par rapport aux fonctions d'activation Tanh et Sigmoid:\n",
        "\n",
        "* Sigmoid et Tanh ont des problèmes de de disparition gradient  (apprenants lents) par rapport à ReLU car ils approchent tous les deux de 1 à une valeur d'entrée supérieure à 3\n",
        "\n",
        "* La fonction d'activation Sigmoïde n'a de valeurs positives que pour les valeurs d'entrée inférieures à 0.\n",
        "\n",
        "* Les fonctions ReLU sont efficaces pour le calcul\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82EgkaIbCu4i"
      },
      "source": [
        "## Fully connected layers\n",
        "\n",
        "Les couches entièrement connectées, également appelées couches denses, connectent chaque neurone connecté de la couche actuelle à chaque neurone connecté de la couche précédente en leur appliquant un poids et un biais. Le vecteur des poids et des biais s'appelle un filtre."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7QSm92dDCd7"
      },
      "source": [
        "## Regularization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k1MDz_CbDDpf"
      },
      "source": [
        "La régularisation est une technique utilisée pour réduire le surapprentissage. Pour ce faire, il ajoute un terme supplémentaire à la fonction d'erreur du modèle (sortie du modèle - valeur apprise) pour empêcher les paramètres de poids du modèle de prendre des valeurs extrêmes pendant l'apprentissage. Trois types de régularisation sont utilisés dans les CNN.\n",
        "\n",
        "* **Régularisation L1** : Pour chaque poids du modèle, w, un paramètre supplémentaire, λ|w|, est ajouté à l'objectif du modèle. Cette régularisation rend le facteur de pondération clairsemé (proche de zéro) lors de l'optimisation\n",
        "\n",
        "* **Régularisation L2** : Pour chaque poids du modèle, w, un paramètre supplémentaire, 1/2λ $w^2$, est ajouté à l'objectif du modèle. Cette régularisation rend le facteur de poids diffusé lors de l'optimisation. On peut s'attendre à ce que les régularisations L2 donnent des performances supérieures aux régularisations L1\n",
        "\n",
        "* **Max norm constraints** Ce type de régularisation ajoute une borne maximale aux poids du CNN pour que |w| < c, où c peut être 3 ou 4. Les contraintes de norme max empêchent le réseau de neurones de sur-apprentissage même lorsque les taux d'apprentissage sont élevés"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULTl0xdEFKlf"
      },
      "source": [
        "## Dropout \n",
        "Le dropout est un type spécial de régularisation et fait référence à l'ignorance des neurones dans le réseau de neurones. Une couche entièrement connectée avec dropout = 0,2 signifie que seulement 80% des neurones entièrement connectés sont connectés à la couche suivante. Les neurones sont abandonnés à l'étape actuelle mais sont actifs à l'étape suivante. Le dropout empêche le réseau d'être dépendant d'un petit nombre de neurones, empêchant ainsi le surapprentissage. Le dropout est appliqué aux neurones d'entrée, mais pas aux neurones de sortie. Le schéma suivant montre le réseau de neurones avec et sans dropout:\n",
        "\n",
        "<img src='https://miro.medium.com/max/518/0*EY8R7nS10y5kQzOx' width=500px>\n",
        "\n",
        "Voici les avantages de dropout :\n",
        "\n",
        "* Dropout force le réseau de neurones à apprendre des fonctionnalités plus robustes. \n",
        "* Le temps d'entraînement pour chaque époque est inférieur, mais le nombre d'itérations double.\n",
        "\n",
        "* Dropout entraîne une augmentation de la précision - d'environ 1 à 2 %\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bsBIjMygG2UO"
      },
      "source": [
        "# Internal covariance shift and batch normalization\n",
        "Pendant l'entraînement, la distribution des entrées de chaque couche change à mesure que le facteur de poids de la couche précédente change, ce qui ralentit l'entraînement. En effet, cela nécessite un taux d'apprentissage et une sélection de facteur de poids inférieurs. Sergey Ioffe et Christian Szegedy ont appelé ce phénomène le changement de covariance interne dans leur article intitulé Batch Normalization: Accelerating Deep Network Training by Reducing Internal Co-variance Shift. Pour plus de détails, consultez :https://arxiv.org/abs/1502.03167.\n",
        "\n",
        "La normalisation par lot résout le problème du décalage de covariance en soustrayant la moyenne du lot de la couche précédente de l'entrée actuelle et en la divisant par l'écart type du lot. Cette nouvelle entrée est ensuite multipliée par le facteur de pondération actuel et ajoutée par le terme de biais pour former la sortie. Le diagramme suivant montre la fonction de sortie intermédiaire du réseau neuronal, avec normalisation de lot.\n",
        "\n",
        "\n",
        "<img src='https://realelectricwizard.files.wordpress.com/2019/03/img_0042.jpg' width=500px>\n",
        "\n",
        "Lorsque la normalisation par lots est appliquée, nous calculons la moyenne (μ) et la variance (σ) sur l'ensemble du mini-lot de taille m. Ensuite, avec ces informations, nous calculons l'entrée normalisée. La sortie du mini-lot est calculée comme l'échelle (γ) multipliée par l'entrée normalisée, plus le décalage (β). Dans TensorFlow, cela peut être exprimé comme suit. Tous les termes ont été expliqués dans le schéma précédent à l'exception de la variance epsilon, qui est le terme ε dans le calcul d'entrée normalisé pour éviter la division par zéro\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_m_N5K1gL09w"
      },
      "source": [
        "tf.nn.batch_normalization(x,mean,variance,offset,scale,variance_epsilon,name=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KgcnU8UfMEy6"
      },
      "source": [
        "Les avantages de la normalisation par lots ont été expliqués en détail par ShibaniSanturkar, Dimitris Tsipras, Andrew Ilyas et Aleksander Madry from MIT dans leur article intitulé How Does Batch Normalization Help Optimization ?. Les détails de l'article peuvent être trouvés sur https://arxiv.org/abs/1805.11604.\n",
        "\n",
        "\n",
        "Les auteurs de l'article ont découvert que la normalisation par lots ne réduit pas le décalage de covariance interne. La vitesse d'apprentissage dans la normalisation par lots peut être attribuée à la régularité de l'entrée due à l'utilisation d'entrées normalisées plutôt que de données d'entrée régulières, qui peuvent présenter de grandes variations en raison de plis,et de minima ou maxima locaux. Cela rend l'algorithme de descente de gradient plus stable, lui permettant ainsi d'utiliser des pas plus grands pour une convergence plus rapide. Cela garantit qu'il ne rencontre aucune erreur"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WwBa_e1lNibU"
      },
      "source": [
        "# Softmax\n",
        "Softmax est une fonction d'activation qui est utilisée dans la couche finale d'un CNN. Il est représenté par l'équation suivante, où P est la probabilité de chaque classe et n est le nombre total de classes:\n",
        "\n",
        "$$ P_i =\\frac{e^{y_i}}{\\sum_{i=0}^ne^{y_i}} $$"
      ]
    }
  ]
}