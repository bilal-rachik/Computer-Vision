{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "feature_extractor.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZPCSoS1847J"
      },
      "source": [
        "# Implémentation d'un extracteur de caractéristiques à l'aide d'un réseau pré-entraîné\n",
        "\n",
        "L'un des moyens les plus simples de profiter de la puissance de l'apprentissage par transfert est d'utiliser des modèles pré-entraînés comme extracteurs de caractéristiques. De cette façon, nous pouvons combiner à la fois l'apprentissage en profondeur et l'apprentissage automatique, ce que nous ne pouvons normalement pas faire, car les algorithmes d'apprentissage automatique traditionnels ne fonctionnent pas avec des images brutes. Dans cette recette, nous allons implémenter une classe FeatureExtractor réutilisable pour produire un ensemble de données de vecteurs à partir d'un ensemble d'images d'entrée, puis l'enregistrer au format HDF5 incroyablement rapide"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Ei_Cwnv9cE-"
      },
      "source": [
        "Nous utiliserons l'ensemble de données Stanford Cars, que vous pouvez télécharger ici : https://www.kaggle.com/jessicali9530/stanford-cars-dataset. Décompressez les données à l'emplacement de votre choix."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bRYdAud89lRv"
      },
      "source": [
        "!pip install -q kaggle"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqIJUkny9oy7"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "#files.upload()"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h6UWllU89q-K",
        "outputId": "b45a4c7a-44e3-459c-e34e-179e66b60102"
      },
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!ls ~/.kaggle\n",
        "!chmod 600 /root/.kaggle/kaggle.json"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "kaggle.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z076_AYo92YG",
        "outputId": "9c7b9a22-9257-4142-89b4-774c3dff665c"
      },
      "source": [
        "!kaggle datasets download -d jessicali9530/stanford-cars-dataset"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading stanford-cars-dataset.zip to /content\n",
            "100% 1.82G/1.82G [00:21<00:00, 82.6MB/s]\n",
            "100% 1.82G/1.82G [00:21<00:00, 90.0MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6sFUNdbhCT5K"
      },
      "source": [
        "#!unzip stanford-cars-dataset.zip"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQfeo9z1CyDc"
      },
      "source": [
        "Nous stockerons les caractéristiques extraites au format HDF5, un protocole hiérarchique binaire conçu pour stocker de très grands ensembles de données numériques sur disque, tout en conservant la facilité d'accès et de calcul au niveau des lignes. Vous pouvez en savoir plus sur HDF5 ici : https://portal.hdfgroup.org/display/HDF5/HDF5."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pYwNx_yRDHG6"
      },
      "source": [
        "Suivez ces étapes pour terminer cette recette :"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVfIxRadDL6T"
      },
      "source": [
        "**1.** Importez tous les packages nécessaires :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OuClnag4DXjz"
      },
      "source": [
        "import glob\n",
        "import os\n",
        "import pathlib\n",
        "\n",
        "import h5py\n",
        "import numpy as np\n",
        "import sklearn.utils as skutils\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.applications import imagenet_utils\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.preprocessing.image import *\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cuOxjM_TDebq"
      },
      "source": [
        "**2.** Dénissez la classe FeatureExtractor et son constructeur :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aO-kdpMBDhYc"
      },
      "source": [
        "class FeatureExtractor(object):\n",
        "    def __init__(self,\n",
        "                 model,\n",
        "                 input_size,\n",
        "                 label_encoder,\n",
        "                 num_instances,\n",
        "                 feature_size,\n",
        "                 output_path,\n",
        "                 features_key='features',\n",
        "                 buffer_size=1000):\n",
        "      \n",
        "        #Nous devons nous assurer que le chemin de sortie peut être écrit\n",
        "\n",
        "        if os.path.exists(output_path):\n",
        "            error_msg = (f'{output_path} already exists. '\n",
        "                         f'Please delete it and try again.')\n",
        "            raise FileExistsError(error_msg)\n",
        "        # Maintenant, stockons le paramètre d'entrée en tant objet\n",
        "        self.model = model\n",
        "        self.input_size = input_size\n",
        "        self.le = label_encoder\n",
        "        self.feature_size = feature_size\n",
        "        \n",
        "        # self.buffer contiendra un tampon d'instances et d'étiquettes, \n",
        "        #tandis que self.current_index pointera vers le prochain emplacement\n",
        "        # libre dans les ensembles de données de la base de données interne HDF5. Nous allons créer ceci maintenant :\n",
        "\n",
        "        self.db = h5py.File(output_path, 'w')\n",
        "        self.features = self.db.create_dataset(features_key,\n",
        "                                               (num_instances,\n",
        "                                                feature_size),\n",
        "                                               dtype='float')\n",
        "        \n",
        "        self.labels = self.db.create_dataset('labels',\n",
        "                                             (num_instances,),\n",
        "                                             dtype='int')\n",
        "\n",
        "        self.buffer_size = buffer_size\n",
        "        self.buffer = {'features': [], 'labels': []}\n",
        "        self.current_index = 0\n",
        "\n",
        "    # Définir une méthode qui extraira les caractéristiques et les étiquettes d'une liste de chemins d'images et les stockera dans la base de données HDF5\n",
        "    def extract_features(self,\n",
        "                         image_paths,\n",
        "                         labels,\n",
        "                         batch_size=64,\n",
        "                         shuffle=True):\n",
        "        if shuffle:\n",
        "            image_paths, labels = skutils.shuffle(image_paths,\n",
        "                                                  labels)\n",
        "            \n",
        "        encoded_labels = self.le.fit_transform(labels)\n",
        "        self._store_class_labels(self.le.classes_)\n",
        "\n",
        "        # Après avoir mélangé les chemins d'images et leurs étiquettes,\n",
        "        # ainsi que l'encodage et le stockage de ces derniers, nous itérerons sur des lots d'images, en les passant à travers le réseau pré-entraîné. \n",
        "        #Une fois cela fait, nous enregistrerons les fonctionnalités résultantes dans la base de données HDF5 (les méthodes d'aide que nous avons utilisées ici seront définies sous peu)\n",
        "\n",
        "        for i in tqdm(range(0, len(image_paths), batch_size)):\n",
        "\n",
        "            batch_paths = image_paths[i: i + batch_size]\n",
        "            batch_labels = encoded_labels[i:i + batch_size]\n",
        "            batch_images = []\n",
        "\n",
        "            for image_path in batch_paths:\n",
        "                image = load_img(image_path,\n",
        "                                 target_size=self.input_size)\n",
        "                image = img_to_array(image)\n",
        "                image = np.expand_dims(image, axis=0)\n",
        "                image = imagenet_utils.preprocess_input(image)\n",
        "\n",
        "                batch_images.append(image)\n",
        "\n",
        "            batch_images = np.vstack(batch_images)\n",
        "            feats = self.model.predict(batch_images,\n",
        "                                       batch_size=batch_size)\n",
        "\n",
        "            new_shape = (feats.shape[0], self.feature_size)\n",
        "            feats = feats.reshape(new_shape)\n",
        "            self._add(feats, batch_labels)\n",
        "\n",
        "        self._close()\n",
        "    # Définir une méthode privée qui ajoutera des entités et des étiquettes aux jeux de données correspondants\n",
        "    def _add(self, rows, labels):\n",
        "        self.buffer['features'].extend(rows)\n",
        "        self.buffer['labels'].extend(labels)\n",
        "\n",
        "        if len(self.buffer['features']) >= self.buffer_size:\n",
        "            self._flush()\n",
        "    # Définir une méthode privée qui videra le buffer sur le disque\n",
        "    def _flush(self):\n",
        "        next_index = (self.current_index +\n",
        "                      len(self.buffer['features']))\n",
        "        buffer_slice = slice(self.current_index, next_index)\n",
        "        self.features[buffer_slice] = self.buffer['features']\n",
        "        self.labels[buffer_slice] = self.buffer['labels']\n",
        "        self.current_index = next_index\n",
        "        self.buffer = {'features': [], 'labels': []}\n",
        "    # Définir une méthode privée qui stockera les étiquettes de classe dans la base de données HDF5\n",
        "    def _store_class_labels(self, class_labels):\n",
        "        data_type = h5py.special_dtype(vlen=np.dtype('int32'))\n",
        "        label_ds = self.db.create_dataset('label_names',\n",
        "                                          (len(class_labels),),\n",
        "                                          dtype=data_type)\n",
        "        label_ds[:] = class_labels\n",
        "    # Définir une méthode privée qui fermera le jeu de données HDF5\n",
        "    def _close(self):\n",
        "        if len(self.buffer['features']) > 0:\n",
        "            self._flush()\n",
        "\n",
        "        self.db.close()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oGUXlp3pHL_4"
      },
      "source": [
        "**3.** Charger les chemins vers les images dans le jeu de données"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zH4O7UxLF12h"
      },
      "source": [
        "files_pattern = (pathlib.Path('/content/') /'cars_train/cars_train' / '*.jpg')\n",
        "files_pattern = str(files_pattern)\n",
        "input_paths = [*glob.glob(files_pattern)]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5GoXs2XMIKTY"
      },
      "source": [
        "**4.** Créez le répertoire de sortie. Nous allons créer un ensemble de données d'images de voitures tournées afin qu'un classificateur potentiel puisse apprendre à rétablir correctement les photos dans leur orientation d'origine, en prédisant correctement l'angle de rotation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AMpsUlYSIV6O"
      },
      "source": [
        "output_path = pathlib.Path('/content/') / 'car_ims_rotated'"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R0YdMj_zInSY"
      },
      "source": [
        "**5.**Créez une copie du jeu de données avec des rotations aléatoires effectuées sur les images :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vppt0ZdrI0MR",
        "outputId": "4b8ebedd-bba3-4e81-8ba9-ec157771c746"
      },
      "source": [
        "if not os.path.exists(str(output_path)):\n",
        "    os.mkdir(str(output_path))\n",
        "\n",
        "labels = []\n",
        "output_paths = []\n",
        "for index in tqdm(range(len(input_paths))):\n",
        "    image_path = input_paths[index]\n",
        "    image = load_img(image_path)\n",
        "    rotation_angle = np.random.choice([0, 90, 180, 270])\n",
        "\n",
        "    rotated_image = image.rotate(rotation_angle)\n",
        "    rotated_image_path = str(output_path / f'{index}.jpg')\n",
        "    rotated_image.save(rotated_image_path, 'JPEG')\n",
        "\n",
        "    output_paths.append(rotated_image_path)\n",
        "    labels.append(rotation_angle)\n",
        "\n",
        "    image.close()\n",
        "    rotated_image.close()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8144/8144 [03:20<00:00, 40.63it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-YUTc6mJI8b"
      },
      "source": [
        "**6.** Instanciez FeatureExtractor tout en utilisant un réseau VGG16 pré-entraîné pour extraire des caractéristiques des images de l'ensemble de données\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s0w9HeqdJMbv",
        "outputId": "255b1dc6-25fc-41c9-ed9e-456a96badb39"
      },
      "source": [
        "features_path = str(output_path / 'features.hdf5')\n",
        "model = VGG16(weights='imagenet', include_top=False)\n",
        "fe = FeatureExtractor(model=model,\n",
        "                      input_size=(224, 224, 3),\n",
        "                      label_encoder=LabelEncoder(),\n",
        "                      num_instances=len(input_paths),\n",
        "                      feature_size=512 * 7 * 7,\n",
        "                      output_path=features_path)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 0s 0us/step\n",
            "58900480/58889256 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m0s4VeUTKT_b"
      },
      "source": [
        "**7.** Extrayez les caractéristiques et les étiquettes :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iwgj6wvcKZWk",
        "outputId": "2e10bf40-78f2-49b5-f367-7b15e920f2ef"
      },
      "source": [
        "fe.extract_features(image_paths=output_paths,\n",
        "                    labels=labels)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 128/128 [43:57<00:00, 20.60s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9JzIhDSnhL1V"
      },
      "source": [
        "Après quelques minutes, il devrait y avoir un fichier nommé features.hdf5 dans //content/car_ims_rotated"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ZDQzdGVhhBW"
      },
      "source": [
        "Dans cette recette, nous avons implémenté un composant réutilisable afin d'utiliser des réseaux pré-entraînés sur ImageNet, tels que VGG16 et ResNet, comme extracteurs de caractéristiques. C'est un excellent moyen d'exploiter les connaissances codées dans ces modèles, car cela nous permet d'utiliser les vecteurs de haute qualité résultants pour former des modèles d'apprentissage automatique traditionnels tels que la régression logistique et les machines à vecteurs de support.\n",
        "\n",
        "Étant donné que les ensembles de données d'images ont tendance à être trop volumineux pour être stockés en mémoire, nous avons eu recours au format HDF5 hautes performances et convivial, idéal pour stocker de grandes données numériques sur disque, tout en conservant la facilité d'accès typique de NumPy. . Cela signifie que nous pouvons interagir avec les ensembles de données HDF5 comme s'il s'agissait de tableaux NumPy normaux, ce qui les rend compatibles avec l'ensemble de l'écosystème SciPy.\n",
        "\n",
        "Le résultat de FeatureExtractor est un fichier HDF5 hiérarchique (considérez-le comme un dossier dans un système de fichiers) contenant trois ensembles de données : features, qui contient les vecteurs de fonctionnalités, labels, qui stockent les labels codés, et label_names, qui contient le -étiquettes lisibles avant l'encodage.\n",
        "\n",
        "Enfin, nous avons utilisé FeatureExtractor pour créer une représentation binaire d'un ensemble de données d'images de voitures pivotées de 0º, 90º, 180º ou 270º."
      ]
    }
  ]
}