{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train_classifier.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TAB_hPeWi_IK"
      },
      "source": [
        "# Entraîner un classificateur simple sur les caractéristiques extraites\n",
        "\n",
        "Les algorithmes d'apprentissage automatique ne sont pas correctement équipés pour fonctionner avec des tenseurs, ce qui leur interdit d'apprendre directement à partir d'images. Cependant, en utilisant des réseaux pré-entraînés comme extracteurs de caractéristiques, nous comblons cet écart, nous permettant d'accéder à la puissance d'algorithmes largement populaires et testés au combat tels que la régression logistique, les arbres de décision et les machines à vecteurs de support.\n",
        "\n",
        "Dans cette recette, nous allons utiliser les fonctionnalités que nous avons générées dans la recette précédente (au format HDF5) pour entraîner un détecteur d'orientation d'image à corriger les degrés de rotation d'une image, pour restaurer son état d'origine."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0OJhh9WlMSL"
      },
      "source": [
        "Comme nous l'avons mentionné dans l'introduction de ce reipce, nous utiliserons le jeu de données features.hdf5 que nous avons généré dans la recette précédente, qui contient des informations codées sur les images pivotées du jeu de données Stanford Cars. Nous supposons que l'ensemble de données se trouve à l'emplacement suivant : /content/car_ims_rotated/features.hdf5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WeEDVLRHlb-i"
      },
      "source": [
        "Suivez ces étapes pour terminer cette recette :"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kUFdQH5Ylc41"
      },
      "source": [
        "**1.** Importez les packages requis :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1lKYpLrlivl"
      },
      "source": [
        "import pathlib\n",
        "\n",
        "import h5py\n",
        "from sklearn.linear_model import LogisticRegressionCV\n",
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ya0nioCTlr_K"
      },
      "source": [
        "**2.** Chargez le jeu de données au format HDF5 :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebKzofYglyFU"
      },
      "source": [
        "dataset_path = str(pathlib.Path('/content/car_ims_rotated/features.hdf5'))\n",
        "                   \n",
        "db = h5py.File(dataset_path, 'r')"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jPKNcy63nMBr"
      },
      "source": [
        "**3.** L'ensemble de données étant trop volumineux, nous ne travaillerons qu'avec 50 % des données. Le bloc suivant divise à la fois les entités et les étiquettes en deux :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LsV2JnkHnaxh"
      },
      "source": [
        "SUBSET_INDEX = int(db['labels'].shape[0] * 0.5)\n",
        "features = db['features'][:SUBSET_INDEX]\n",
        "labels = db['labels'][:SUBSET_INDEX]"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKQxzG3Ongm0"
      },
      "source": [
        "**4.** Prenez les premiers 80 % des données pour entraîner le modèle et les 20 % restants pour l'évaluer plus tard :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNFfMV88nkLE"
      },
      "source": [
        "TRAIN_PROPORTION = 0.8\n",
        "SPLIT_INDEX = int(len(labels) * TRAIN_PROPORTION)\n",
        "\n",
        "X_train, y_train = (features[:SPLIT_INDEX],\n",
        "                    labels[:SPLIT_INDEX])\n",
        "X_test, y_test = (features[SPLIT_INDEX:],\n",
        "                  labels[SPLIT_INDEX:])"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jw5YF0JwntgU"
      },
      "source": [
        "**5.** Former un modèle de régression logistique à validation croisée sur l'ensemble d'apprentissage. LogisticRegressionCV trouvera le meilleur paramètre C en utilisant la validation croisée :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cmo1DlecoDqt",
        "outputId": "29cb4bde-b98c-46f0-a4f2-064928944acf"
      },
      "source": [
        "model = LogisticRegressionCV(n_jobs=-1)\n",
        "model.fit(X_train, y_train)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegressionCV(Cs=10, class_weight=None, cv=None, dual=False,\n",
              "                     fit_intercept=True, intercept_scaling=1.0, l1_ratios=None,\n",
              "                     max_iter=100, multi_class='auto', n_jobs=-1, penalty='l2',\n",
              "                     random_state=None, refit=True, scoring=None,\n",
              "                     solver='lbfgs', tol=0.0001, verbose=0)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BxbAD7yioMbw"
      },
      "source": [
        "Notez que n_jobs=-1 signifie que nous utiliserons tous les cœurs disponibles pour trouver le meilleur modèle en parallèle. Vous pouvez ajuster cette valeur en fonction de la capacité de votre matériel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jp28idEKoUmQ"
      },
      "source": [
        "**6.** Évaluez le modèle sur l'ensemble de test. Nous allons calculer un rapport de classification pour obtenir une vue précise des performances du modèle :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V5eOFnrooXWM",
        "outputId": "105077e5-9ccc-4e2c-9622-38edd472dc3e"
      },
      "source": [
        "predictions = model.predict(X_test)\n",
        "#report = classification_report(y_test, predictions,\n",
        "#                               target_names=db['label_names'])\n",
        "report = classification_report(y_test, predictions,\n",
        "                               target_names=['0', '90', '180', '270'])\n",
        "print(report)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       226\n",
            "          90       0.98      0.98      0.98       184\n",
            "         180       0.99      1.00      1.00       202\n",
            "         270       0.99      0.98      0.98       203\n",
            "\n",
            "    accuracy                           0.99       815\n",
            "   macro avg       0.99      0.99      0.99       815\n",
            "weighted avg       0.99      0.99      0.99       815\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3TXDPYgpoguV"
      },
      "source": [
        "Le modèle fait un bon travail de discrimination entre les quatre classes, atteignant une précision globale de 99% sur l'ensemble de test !"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fuIsyXkholyF"
      },
      "source": [
        "**7.** Enfin, fermez le chier HDF5 pour libérer des ressources :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWS5TJkJoxIO"
      },
      "source": [
        "db.close()"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8LDeSyv4o3tT"
      },
      "source": [
        "Nous venons d'entraîner un modèle de régression logistique très simple pour détecter le degré de rotation d'une image. Pour y parvenir, nous avons tiré parti des fonctionnalités riches et expressives que nous avons extraites à l'aide d'un réseau VGG16 pré-entraîné sur ImageNet.\n",
        "\n",
        "Étant donné que ces données sont trop volumineuses et que les algorithmes d'apprentissage automatique de scikit-learn fonctionnent avec l'intégralité des données en une seule fois (plus précisément, la plupart d'entre eux ne peuvent pas fonctionner par lots), nous n'avons utilisé que 50 % des fonctionnalités et des étiquettes, en raison de contraintes de mémoire.\n",
        "\n",
        "Après quelques minutes, nous avons obtenu une performance incroyable de 99% sur l'ensemble de test. De plus, en analysant le rapport de classification, nous pouvons voir que le modèle est très conant dans ses prédictions, atteignant un score F1 d'au moins 0,99 dans les quatre cas"
      ]
    }
  ]
}