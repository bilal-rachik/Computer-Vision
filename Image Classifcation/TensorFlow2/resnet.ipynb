{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "resnet.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UzHY02A73FAU"
      },
      "source": [
        "# Implémentation de ResNet à partir de zéro\n",
        "\n",
        "Residual Network, ou ResNet en abrégé, constitue l'une des avancées les plus révolutionnaires en matière d'apprentissage en profondeur. Cette architecture repose sur un composant appelé module résiduel, qui nous permet d'ensemble des réseaux avec des profondeurs impensables il y a quelques années. Il existe des variantes de ResNet qui ont plus de 100 couches, sans aucune perte de performances !\n",
        "\n",
        "\n",
        "Dans cette recette, nous allons implémenter ResNet à partir de zéro et le former sur le remplacement difficile de CIFAR-10, CINIC-10\n",
        "\n",
        "Nous n'expliquerons pas ResNet en profondeur, c'est donc une bonne idée de vous familiariser avec l'architecture si vous êtes intéressé par les détails. Vous pouvez lire l'article original ici : https://arxiv.org/abs/1512.03385.\n",
        "\n",
        "Suivez ces étapes pour mettre en œuvre ResNet à partir de zéro :\n",
        "**1.** Importez tous les modules nécessaires :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5bSGEbmHlkD"
      },
      "source": [
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import tarfile\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import *\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.utils import get_file"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tUa_e5fiHxSP"
      },
      "source": [
        "**2.** Dénissez un alias à l'option tf.data.expertimental.AUTOTUNE, que nous utiliserons plus tard :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "umRABLvyH1lB"
      },
      "source": [
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "TRAIN = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XY_4NIOuH8hu"
      },
      "source": [
        "**3.** Dénissez une fonction pour créer un module résiduel dans l'architecture ResNet. Commençons par spécifier la signature de la fonction et implémenter le premier bloc :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "buJ6CKsyIKyG"
      },
      "source": [
        "def residual_module(data,\n",
        "                    filters,\n",
        "                    stride,\n",
        "                    reduce=False,\n",
        "                    reg=0.0001,\n",
        "                    bn_eps=2e-5,\n",
        "                    bn_momentum=0.9):\n",
        "    # The shortcut branch of the ResNet module should be\n",
        "    # initialized as the input (identity) data\n",
        "    shortcut = data\n",
        "\n",
        "    # The first block of the Resnet module are the 1x1 CONVs\n",
        "    bn_1 = BatchNormalization(axis=-1,\n",
        "                              epsilon=bn_eps,\n",
        "                              momentum=bn_momentum)(data)\n",
        "    act_1 = ReLU()(bn_1)\n",
        "    conv_1 = Conv2D(filters=int(filters / 4.),\n",
        "                    kernel_size=(1, 1),\n",
        "                    use_bias=False,\n",
        "                    kernel_regularizer=l2(reg))(act_1)\n",
        "\n",
        "    # ResNet's module second block are 3x3 convolutions.\n",
        "    bn_2 = BatchNormalization(axis=-1,\n",
        "                              epsilon=bn_eps,\n",
        "                              momentum=bn_momentum)(conv_1)\n",
        "    act_2 = ReLU()(bn_2)\n",
        "    conv_2 = Conv2D(filters=int(filters / 4.),\n",
        "                    kernel_size=(3, 3),\n",
        "                    strides=stride,\n",
        "                    padding='same',\n",
        "                    use_bias=False,\n",
        "                    kernel_regularizer=l2(reg))(act_2)\n",
        "\n",
        "    # The third block of the ResNet module is another set of\n",
        "    # 1x1 convolutions.\n",
        "    bn_3 = BatchNormalization(axis=-1,\n",
        "                              epsilon=bn_eps,\n",
        "                              momentum=bn_momentum)(conv_2)\n",
        "    act_3 = ReLU()(bn_3)\n",
        "    conv_3 = Conv2D(filters=filters,\n",
        "                    kernel_size=(1, 1),\n",
        "                    use_bias=False,\n",
        "                    kernel_regularizer=l2(reg))(act_3)\n",
        "\n",
        "    # If we are to reduce the spatial size, apply a 1x1\n",
        "    # convolution to the shortcut\n",
        "    if reduce:\n",
        "        shortcut = Conv2D(filters=filters,\n",
        "                          kernel_size=(1, 1),\n",
        "                          strides=stride,\n",
        "                          use_bias=False,\n",
        "                          kernel_regularizer=l2(reg))(act_1)\n",
        "\n",
        "    x = Add()([conv_3, shortcut])\n",
        "\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fH0959RIIpLf"
      },
      "source": [
        "**4.** Dénissez une fonction pour créer un réseau ResNet personnalisé :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pom37VP-Irtf"
      },
      "source": [
        "def build_resnet(input_shape,\n",
        "                 classes,\n",
        "                 stages,\n",
        "                 filters,\n",
        "                 reg=1e-3,\n",
        "                 bn_eps=2e-5,\n",
        "                 bn_momentum=0.9):\n",
        "    inputs = Input(shape=input_shape)\n",
        "    x = BatchNormalization(axis=-1,\n",
        "                           epsilon=bn_eps,\n",
        "                           momentum=bn_momentum)(inputs)\n",
        "\n",
        "    x = Conv2D(filters[0], (3, 3),\n",
        "               use_bias=False,\n",
        "               padding='same',\n",
        "               kernel_regularizer=l2(reg))(x)\n",
        "\n",
        "    for i in range(len(stages)):\n",
        "        # Initialize the stride, then apply a residual module\n",
        "        # used to reduce the spatial size of the input volume.\n",
        "        stride = (1, 1) if i == 0 else (2, 2)\n",
        "        x = residual_module(data=x,\n",
        "                            filters=filters[i + 1],\n",
        "                            stride=stride,\n",
        "                            reduce=True,\n",
        "                            bn_eps=bn_eps,\n",
        "                            bn_momentum=bn_momentum)\n",
        "\n",
        "        # Loop over the number of layers in the stage.\n",
        "        for j in range(stages[i] - 1):\n",
        "            x = residual_module(data=x,\n",
        "                                filters=filters[i + 1],\n",
        "                                stride=(1, 1),\n",
        "                                bn_eps=bn_eps,\n",
        "                                bn_momentum=bn_momentum)\n",
        "\n",
        "    x = BatchNormalization(axis=-1,\n",
        "                           epsilon=bn_eps,\n",
        "                           momentum=bn_momentum)(x)\n",
        "    x = ReLU()(x)\n",
        "    x = AveragePooling2D((8, 8))(x)\n",
        "\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(classes, kernel_regularizer=l2(reg))(x)\n",
        "    x = Softmax()(x)\n",
        "\n",
        "    return Model(inputs, x, name='resnet')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ubYwjbUFJF8m"
      },
      "source": [
        "**5.** Dénissez une fonction pour charger une image et ses étiquettes encodées à One_hot, en fonction de son chemin de chier :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rt879Mp7JPfn"
      },
      "source": [
        "def load_image_and_label(image_path, target_size=(32, 32)):\n",
        "    image = tf.io.read_file(image_path)\n",
        "    image = tf.image.decode_png(image, channels=3)\n",
        "    image = tf.image.convert_image_dtype(image, np.float32)\n",
        "    image -= CINIC_MEAN_RGB  # Mean normalize\n",
        "    image = tf.image.resize(image, target_size)\n",
        "\n",
        "    label = tf.strings.split(image_path, os.path.sep)[-2]\n",
        "    label = (label == CINIC_10_CLASSES)  # One-hot encode.\n",
        "    label = tf.dtypes.cast(label, tf.float32)\n",
        "\n",
        "    return image, label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_gqiZ_JJx7v"
      },
      "source": [
        "**6.** Dénissez une fonction pour créer une instance tf.data.Dataset d'images et d'étiquettes à partir d'un modèle de type glob qui fait référence au dossier où se trouvent les images :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GuGTvA2J5Gs"
      },
      "source": [
        "def prepare_dataset(data_pattern, shuffle=False):\n",
        "    dataset = (tf.data.Dataset\n",
        "               .list_files(data_pattern)\n",
        "               .map(load_image_and_label,\n",
        "                    num_parallel_calls=AUTOTUNE)\n",
        "               .batch(BATCH_SIZE))\n",
        "\n",
        "    if shuffle:\n",
        "        dataset = dataset.shuffle(BUFFER_SIZE)\n",
        "\n",
        "    return dataset.prefetch(BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x29KvwU3KFf4"
      },
      "source": [
        "**7.** Dénir les valeurs RGB moyennes du jeu de données CINIC-10, qui sont utilisées dans la fonction load_image_and_label() pour normaliser les images (cette information est disponible sur le site ofciel CINIC-10)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sASTaQHcKwEw"
      },
      "source": [
        "CINIC_MEAN_RGB = np.array([0.47889522, 0.47227842, 0.43047404])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cXi-Et3-K2pX"
      },
      "source": [
        "**8.** Déﬁnissez les classes du jeu de données CINIC-10 :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kK_C_UgrK12u"
      },
      "source": [
        "CINIC_10_CLASSES = ['airplane', 'automobile', 'bird', 'cat',\n",
        "                    'deer', 'dog', 'frog', 'horse', 'ship',\n",
        "                    'truck']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "glCUSV6rLEjR"
      },
      "source": [
        "**9.** Téléchargez et extrayez le jeu de données CINIC-10 dans le répertoire à votre choix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Skxd5MKKLJ_w",
        "outputId": "c71645c3-d0a4-4f90-8570-7ac9c704699c"
      },
      "source": [
        "DATASET_URL = (\"https://datashare.is.ed.ac.uk/bitstream/handle/10283/3192/CINIC-10.tar.gz?sequence=4&isAllowed=y\")\n",
        "\n",
        "DATA_NAME = 'cinic10'\n",
        "FILE_EXTENSION = 'tar.gz'\n",
        "FILE_NAME = '.'.join([DATA_NAME, FILE_EXTENSION])\n",
        "\n",
        "downloaded_file_location = get_file(origin=DATASET_URL,\n",
        "                                    fname=FILE_NAME,\n",
        "                                    extract=False)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://datashare.is.ed.ac.uk/bitstream/handle/10283/3192/CINIC-10.tar.gz?sequence=4&isAllowed=y\n",
            "687546368/687544992 [==============================] - 1713s 2us/step\n",
            "687554560/687544992 [==============================] - 1713s 2us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CIhvkPZuLz6W"
      },
      "source": [
        "data_directory, _ = (downloaded_file_location\n",
        "                     .rsplit(os.path.sep, maxsplit=1))\n",
        "data_directory = os.path.sep.join([data_directory, DATA_NAME])\n",
        "tar = tarfile.open(downloaded_file_location)\n",
        "if not os.path.exists(data_directory):\n",
        "  tar.extractall(data_directory)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oMEGNSBpMKx6"
      },
      "source": [
        "**10.** Définissez les modèles de type glob pour les sous-ensembles d'entraînement, de test et de validation "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6CmcCHdMSG1"
      },
      "source": [
        "train_pattern = os.path.sep.join(\n",
        "    [data_directory, 'train/*/*.png'])\n",
        "test_pattern = os.path.sep.join(\n",
        "    [data_directory, 'test/*/*.png'])\n",
        "valid_pattern = os.path.sep.join(\n",
        "    [data_directory, 'valid/*/*.png'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O0VuaWZ3MXKy"
      },
      "source": [
        "**11.** Préparez les ensembles de données :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8eoL9GDMcUB"
      },
      "source": [
        "BATCH_SIZE = 128\n",
        "BUFFER_SIZE = 1024\n",
        "train_dataset = prepare_dataset(train_pattern, shuffle=True)\n",
        "test_dataset = prepare_dataset(test_pattern)\n",
        "valid_dataset = prepare_dataset(valid_pattern)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wwQoaS5CMlyN"
      },
      "source": [
        "**12.** Construisez, compilez et entraînez un modèle ResNet. Comme il s'agit d'un processus qui prend du temps, nous enregistrerons une version du modèle après chaque époque, en utilisant le rappel ModelCheckpoint() :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fM3-HMjEMzMV",
        "outputId": "9a2f2878-7b6f-4238-c1b7-b0c8b087ce99"
      },
      "source": [
        "TRAIN = False\n",
        "if TRAIN:\n",
        "    model = build_resnet(input_shape=(32, 32, 3),\n",
        "                         classes=10,\n",
        "                         stages=(9, 9, 9),\n",
        "                         filters=(64, 64, 128, 256),\n",
        "                         reg=5e-3)\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='rmsprop',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    model_checkpoint_callback = ModelCheckpoint(\n",
        "        filepath='./model.{epoch:02d}-{val_accuracy:.2f}.hdf5',\n",
        "        save_weights_only=False,\n",
        "        monitor='val_accuracy')\n",
        "\n",
        "    EPOCHS = 2\n",
        "    model.fit(train_dataset,\n",
        "              validation_data=valid_dataset,\n",
        "              epochs=EPOCHS,\n",
        "              callbacks=[model_checkpoint_callback])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kC9-ipQCM7Lc"
      },
      "source": [
        "**13.** Chargez le meilleur modèle et évaluez-le sur l'ensemble de test "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vuo0mUMoNCw7"
      },
      "source": [
        "model = load_model('model.38-0.72.hdf5')\n",
        "result = model.evaluate(test_dataset)\n",
        "print(f'Test accuracy: {result[1]}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trCKdiXmNO0q"
      },
      "source": [
        "La clé de ResNet est le module résiduel, que nous avons implémenté à l'étape 3. Un module résiduel est une micro-architecture qui peut être réutilisée plusieurs fois pour créer une macro-architecture, atteignant ainsi de grandes profondeurs. La fonction résiduelle_module() reçoit les données d'entrée (data), le nombre de filtres, le stride des blocs convolutifs, un indicateur de réduction pour indiquer si l'on veut réduire la taille spatiale du raccourci branche en appliquant une convolution 1x1 (une technique utilisée pour réduire la dimensionnalité des volumes de sortie des filtres), et des paramètres pour ajuster la quantité de régularisation (reg) et de normalisation par lots appliquée aux diférentes couches (bn_eps et bn_momentum) .\n",
        "\n",
        "Un module résiduel comprend deux branches : la première est la connexion de saut(skip), également appelée branche de raccourci, qui est fondamentalement la même que l'entrée. La seconde ou branche principale est composée de trois blocs de convolution : un 1x1 avec un quart des filtres, un 3x3, également avec un quart des filtres, et enfin un autre 1x1, qui utilise tous les filtres. Le raccourci et les branches principales sont finalement concaténés à l'aide de la couche Add().\n",
        "\n",
        "build_network() permet de spécifier le nombre d'étapes à utiliser, ainsi que le nombre de filter par étape. Nous commençons par appliquer une convolution 3x3 à l'entrée (après avoir été normalisée par lot). Ensuite, nous procédons à la création des étapes. Un étage est une série de modules résiduels connectés les uns aux autres. La longueur de la liste des étapes contrôle le nombre d'étapes à créer, et chaque élément de cette liste contrôle le nombre de couches dans cette étape particulière. Le paramètre de filtres contient le nombre de filtres à utiliser dans chaque bloc résiduel d'une étape. Enfin, nous avons construit un réseau entièrement connecté, activé par Sofmax, au-dessus des étages avec autant d'unités qu'il y a de classes dans l'ensemble de données (dans ce cas, 10).\n",
        "\n",
        "Parce que ResNet est une architecture très profonde, lourde et lente à former, nous avons vérifié le modèle après chaque époque. Dans cette recette, nous avons obtenu le meilleur modèle à l'époque 38, qui a produit une précision de 72% sur l'ensemble de test, une performance respectable étant donné que CINIC-10 n'est pas un ensemble de données facile et que nous n'avons appliqué aucune augmentation de données ou transfert d'apprentissage."
      ]
    }
  ]
}