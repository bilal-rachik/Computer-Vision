{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "data_aug_keras.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vP0m5l6WeN2h"
      },
      "source": [
        "# Utilisation de l'augmentation des données pour améliorer les performances avec l'API Keras.\n",
        "\n",
        "Plus souvent qu'autrement, nous pouvons bénéficier de fournir plus de données à notre modèle. Mais les données sont chères et rares. Existe-t-il un moyen de contourner cette limitation ? Oui il y a! Nous pouvons synthétiser de nouveaux exemples d'entraînement en effectuant de petites modifications sur ceux que nous avons déjà, tels que des rotations aléatoires, des recadrages aléatoires et des basculements horizontaux, entre autres. Dans cette recette, nous allons apprendre à utiliser l'augmentation de données avec l'API Keras pour améliorer les performances."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hzEDRf5vesNK"
      },
      "source": [
        "Dans cette recette, nous utiliserons le jeu de données Caltech 101, disponible ici : http://www.vision.caltech.edu/Image_Datasets/Caltech101/. Téléchargez et décompressez 101_ObjectCategories.tar.gz à votre emplacement préféré.\n",
        "\n",
        "https://drive.google.com/u/0/uc?export=download&confirm=k34b&id=137RyRjvTBkBiIfeYBNZBtViDHQ6_Ewsp"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jUexHLNfWW4"
      },
      "source": [
        "#!wget -c http://www.vision.caltech.edu/Image_Datasets/Caltech101/101_ObjectCategories.tar.gz"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2f1NHqlfkWr"
      },
      "source": [
        "#!tar xvf 101_ObjectCategories.tar.gz"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5G9no3Qee6dj"
      },
      "source": [
        "**1.** Importez les modules requis :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ly8Il3zsm04p"
      },
      "source": [
        "#!pip install git+https://github.com/tensorflow/docs"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMgZC9safEjg"
      },
      "source": [
        "import os\n",
        "import pathlib\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow_docs as tfdocs\n",
        "import tensorflow_docs.plots\n",
        "from glob import glob\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing.image import *"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ZRykZTmfLBJ"
      },
      "source": [
        "**2.** Dénissez une fonction pour charger toutes les images de l'ensemble de données, ainsi que leurs étiquettes, en fonction de leurs chemins de fichiers :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDjV_jB0nHy_"
      },
      "source": [
        "def load_images_and_labels(image_paths, target_size=(64, 64)):\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    for image_path in image_paths:\n",
        "        image = load_img(image_path, target_size=target_size)\n",
        "        image = img_to_array(image)\n",
        "\n",
        "        label = image_path.split(os.path.sep)[-2]\n",
        "\n",
        "        images.append(image)\n",
        "        labels.append(label)\n",
        "\n",
        "    return np.array(images), np.array(labels)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6I4e8DojnSZ_"
      },
      "source": [
        "**3.** Dénissez une fonction pour créer une version plus petite de VGG :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mO-8jjynU05"
      },
      "source": [
        "def build_network(width, height, depth, classes):\n",
        "    input_layer = Input(shape=(width, height, depth))\n",
        "\n",
        "    x = Conv2D(filters=32,\n",
        "               kernel_size=(3, 3),\n",
        "               padding='same')(input_layer)\n",
        "    x = ReLU()(x)\n",
        "    x = BatchNormalization(axis=-1)(x)\n",
        "    x = Conv2D(filters=32,\n",
        "               kernel_size=(3, 3),\n",
        "               padding='same')(x)\n",
        "    x = ReLU()(x)\n",
        "    x = BatchNormalization(axis=-1)(x)\n",
        "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "    x = Dropout(rate=0.25)(x)\n",
        "\n",
        "    x = Conv2D(filters=64,\n",
        "               kernel_size=(3, 3),\n",
        "               padding='same')(x)\n",
        "    x = ReLU()(x)\n",
        "    x = BatchNormalization(axis=-1)(x)\n",
        "    x = Conv2D(filters=64,\n",
        "               kernel_size=(3, 3),\n",
        "               padding='same')(x)\n",
        "    x = ReLU()(x)\n",
        "    x = BatchNormalization(axis=-1)(x)\n",
        "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "    x = Dropout(rate=0.25)(x)\n",
        "\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(units=512)(x)\n",
        "    x = ReLU()(x)\n",
        "    x = BatchNormalization(axis=-1)(x)\n",
        "    x = Dropout(rate=0.25)(x)\n",
        "\n",
        "    x = Dense(units=classes)(x)\n",
        "    output = Softmax()(x)\n",
        "\n",
        "    return Model(input_layer, output)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cgNdn1jknhiQ"
      },
      "source": [
        "**4.** Déﬁnissez une fonction pour tracer et enregistrer la courbe d'entraînement d'un modèle :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFKSZiulnnOA"
      },
      "source": [
        "def plot_model_history(model_history, metric, plot_name):\n",
        "    plt.style.use('seaborn-darkgrid')\n",
        "    plotter = tfdocs.plots.HistoryPlotter()\n",
        "    plotter.plot({'Model': model_history}, metric=metric)\n",
        "\n",
        "    plt.title(f'{metric.upper()}')\n",
        "    plt.ylim([0, 1])\n",
        "\n",
        "    plt.savefig(f'{plot_name}.png')\n",
        "    plt.close()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5LWwjPhnxEy"
      },
      "source": [
        "**5.** Définissez la graine aléatoire :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FlKVtrK-ng7y"
      },
      "source": [
        "SEED = 999\n",
        "np.random.seed(SEED)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hfop2RtlpRYi"
      },
      "source": [
        "**6.** Chargez les chemins vers toutes les images de l'ensemble de données, à l'exception de celles de la classe BACKGROUND_Google :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ptgFk6upayq"
      },
      "source": [
        "base_path = (pathlib.Path('/content') / '101_ObjectCategories')\n",
        "images_pattern = str(base_path / '*' / '*.jpg')\n",
        "image_paths = [*glob(images_pattern)]\n",
        "image_paths = [p for p in image_paths if\n",
        "               p.split(os.path.sep)[-2] != 'BACKGROUND_Google']"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nnVHRNn-ppVx"
      },
      "source": [
        "**7.** Calculez l'ensemble des classes dans l'ensemble de données :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CIlqJ5Vopvw5"
      },
      "source": [
        "classes = {p.split(os.path.sep)[-2] for p in image_paths}"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GX1LBij3p3Sq"
      },
      "source": [
        "**8.** Chargez l'ensemble de données en mémoire, normalisez les images et encodez à one-hot les étiquettes :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzlgFDI9qBB5"
      },
      "source": [
        "X, y = load_images_and_labels(image_paths)\n",
        "X = X.astype('float') / 255.0\n",
        "y = LabelBinarizer().fit_transform(y)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JZHLO5goqJsE"
      },
      "source": [
        "**9.** Créez les sous-ensembles d'entraînement et de test :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5kgiTIxqJDo"
      },
      "source": [
        "(X_train, X_test,\n",
        " y_train, y_test) = train_test_split(X, y,\n",
        "                                     test_size=0.2,\n",
        "                                     random_state=SEED)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ChKFIhwyqO4Y"
      },
      "source": [
        "**10.** Construisez, compilez, entraînez et évaluez un réseau de neurones sans augmentation de données :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FOmKakOeqbxL",
        "outputId": "bbd09e69-22b1-4481-c46d-48a69b16a3d5"
      },
      "source": [
        "EPOCHS = 40\n",
        "BATCH_SIZE = 64\n",
        "model = build_network(64, 64, 3, len(classes))\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='rmsprop',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(X_train, y_train,\n",
        "                    validation_data=(X_test, y_test),\n",
        "                    epochs=EPOCHS,\n",
        "                    batch_size=BATCH_SIZE)\n",
        "result = model.evaluate(X_test, y_test)\n",
        "print(f'Test accuracy: {result[1]}')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "109/109 [==============================] - 37s 66ms/step - loss: 2.6393 - accuracy: 0.4450 - val_loss: 5.1800 - val_accuracy: 0.0236\n",
            "Epoch 2/40\n",
            "109/109 [==============================] - 7s 60ms/step - loss: 1.2424 - accuracy: 0.6980 - val_loss: 5.4633 - val_accuracy: 0.0236\n",
            "Epoch 3/40\n",
            "109/109 [==============================] - 7s 60ms/step - loss: 0.5338 - accuracy: 0.8811 - val_loss: 2.9012 - val_accuracy: 0.3957\n",
            "Epoch 4/40\n",
            "109/109 [==============================] - 6s 59ms/step - loss: 0.2015 - accuracy: 0.9607 - val_loss: 2.0907 - val_accuracy: 0.5236\n",
            "Epoch 5/40\n",
            "109/109 [==============================] - 6s 59ms/step - loss: 0.1111 - accuracy: 0.9823 - val_loss: 1.6211 - val_accuracy: 0.6417\n",
            "Epoch 6/40\n",
            "109/109 [==============================] - 6s 60ms/step - loss: 0.0750 - accuracy: 0.9888 - val_loss: 1.8492 - val_accuracy: 0.6331\n",
            "Epoch 7/40\n",
            "109/109 [==============================] - 6s 60ms/step - loss: 0.0530 - accuracy: 0.9929 - val_loss: 1.6784 - val_accuracy: 0.6469\n",
            "Epoch 8/40\n",
            "109/109 [==============================] - 6s 60ms/step - loss: 0.0401 - accuracy: 0.9944 - val_loss: 1.7861 - val_accuracy: 0.6515\n",
            "Epoch 9/40\n",
            "109/109 [==============================] - 6s 59ms/step - loss: 0.0337 - accuracy: 0.9951 - val_loss: 2.0423 - val_accuracy: 0.6175\n",
            "Epoch 10/40\n",
            "109/109 [==============================] - 6s 59ms/step - loss: 0.0305 - accuracy: 0.9965 - val_loss: 1.8419 - val_accuracy: 0.6475\n",
            "Epoch 11/40\n",
            "109/109 [==============================] - 6s 59ms/step - loss: 0.0268 - accuracy: 0.9963 - val_loss: 1.9719 - val_accuracy: 0.6486\n",
            "Epoch 12/40\n",
            "109/109 [==============================] - 7s 60ms/step - loss: 0.0227 - accuracy: 0.9977 - val_loss: 2.5095 - val_accuracy: 0.5743\n",
            "Epoch 13/40\n",
            "109/109 [==============================] - 6s 59ms/step - loss: 0.0208 - accuracy: 0.9974 - val_loss: 3.9733 - val_accuracy: 0.5271\n",
            "Epoch 14/40\n",
            "109/109 [==============================] - 6s 59ms/step - loss: 0.0200 - accuracy: 0.9973 - val_loss: 2.0734 - val_accuracy: 0.6382\n",
            "Epoch 15/40\n",
            "109/109 [==============================] - 7s 60ms/step - loss: 0.0162 - accuracy: 0.9977 - val_loss: 2.0749 - val_accuracy: 0.6319\n",
            "Epoch 16/40\n",
            "109/109 [==============================] - 6s 60ms/step - loss: 0.0171 - accuracy: 0.9973 - val_loss: 2.7387 - val_accuracy: 0.5962\n",
            "Epoch 17/40\n",
            "109/109 [==============================] - 6s 59ms/step - loss: 0.0102 - accuracy: 0.9981 - val_loss: 2.0921 - val_accuracy: 0.6313\n",
            "Epoch 18/40\n",
            "109/109 [==============================] - 6s 59ms/step - loss: 0.0148 - accuracy: 0.9976 - val_loss: 2.3029 - val_accuracy: 0.6123\n",
            "Epoch 19/40\n",
            "109/109 [==============================] - 6s 59ms/step - loss: 0.0091 - accuracy: 0.9990 - val_loss: 2.1665 - val_accuracy: 0.6290\n",
            "Epoch 20/40\n",
            "109/109 [==============================] - 6s 59ms/step - loss: 0.0133 - accuracy: 0.9984 - val_loss: 2.1848 - val_accuracy: 0.6238\n",
            "Epoch 21/40\n",
            "109/109 [==============================] - 7s 60ms/step - loss: 0.0106 - accuracy: 0.9986 - val_loss: 2.3384 - val_accuracy: 0.6215\n",
            "Epoch 22/40\n",
            "109/109 [==============================] - 6s 59ms/step - loss: 0.0113 - accuracy: 0.9988 - val_loss: 2.2903 - val_accuracy: 0.6100\n",
            "Epoch 23/40\n",
            "109/109 [==============================] - 6s 59ms/step - loss: 0.0102 - accuracy: 0.9980 - val_loss: 2.1386 - val_accuracy: 0.6377\n",
            "Epoch 24/40\n",
            "109/109 [==============================] - 6s 59ms/step - loss: 0.0146 - accuracy: 0.9980 - val_loss: 2.4072 - val_accuracy: 0.6100\n",
            "Epoch 25/40\n",
            "109/109 [==============================] - 6s 60ms/step - loss: 0.0109 - accuracy: 0.9983 - val_loss: 2.2042 - val_accuracy: 0.6285\n",
            "Epoch 26/40\n",
            "109/109 [==============================] - 6s 60ms/step - loss: 0.0093 - accuracy: 0.9993 - val_loss: 2.1973 - val_accuracy: 0.6296\n",
            "Epoch 27/40\n",
            "109/109 [==============================] - 6s 59ms/step - loss: 0.0089 - accuracy: 0.9984 - val_loss: 2.1759 - val_accuracy: 0.6354\n",
            "Epoch 28/40\n",
            "109/109 [==============================] - 6s 59ms/step - loss: 0.0083 - accuracy: 0.9986 - val_loss: 2.1637 - val_accuracy: 0.6267\n",
            "Epoch 29/40\n",
            "109/109 [==============================] - 7s 60ms/step - loss: 0.0093 - accuracy: 0.9984 - val_loss: 2.2654 - val_accuracy: 0.6285\n",
            "Epoch 30/40\n",
            "109/109 [==============================] - 6s 59ms/step - loss: 0.0061 - accuracy: 0.9994 - val_loss: 2.3006 - val_accuracy: 0.6285\n",
            "Epoch 31/40\n",
            "109/109 [==============================] - 6s 59ms/step - loss: 0.0062 - accuracy: 0.9990 - val_loss: 2.3332 - val_accuracy: 0.6187\n",
            "Epoch 32/40\n",
            "109/109 [==============================] - 6s 59ms/step - loss: 0.0078 - accuracy: 0.9986 - val_loss: 2.3588 - val_accuracy: 0.6290\n",
            "Epoch 33/40\n",
            "109/109 [==============================] - 6s 59ms/step - loss: 0.0061 - accuracy: 0.9990 - val_loss: 2.2432 - val_accuracy: 0.6377\n",
            "Epoch 34/40\n",
            "109/109 [==============================] - 6s 59ms/step - loss: 0.0071 - accuracy: 0.9988 - val_loss: 2.4876 - val_accuracy: 0.6210\n",
            "Epoch 35/40\n",
            "109/109 [==============================] - 6s 59ms/step - loss: 0.0068 - accuracy: 0.9984 - val_loss: 2.2407 - val_accuracy: 0.6388\n",
            "Epoch 36/40\n",
            "109/109 [==============================] - 6s 59ms/step - loss: 0.0057 - accuracy: 0.9996 - val_loss: 2.5308 - val_accuracy: 0.6146\n",
            "Epoch 37/40\n",
            "109/109 [==============================] - 6s 59ms/step - loss: 0.0073 - accuracy: 0.9991 - val_loss: 2.2296 - val_accuracy: 0.6475\n",
            "Epoch 38/40\n",
            "109/109 [==============================] - 6s 59ms/step - loss: 0.0040 - accuracy: 0.9988 - val_loss: 2.5752 - val_accuracy: 0.6089\n",
            "Epoch 39/40\n",
            "109/109 [==============================] - 6s 59ms/step - loss: 0.0057 - accuracy: 0.9994 - val_loss: 2.5089 - val_accuracy: 0.6198\n",
            "Epoch 40/40\n",
            "109/109 [==============================] - 6s 59ms/step - loss: 0.0043 - accuracy: 0.9993 - val_loss: 2.5987 - val_accuracy: 0.6233\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 2.5987 - accuracy: 0.6233\n",
            "Test accuracy: 0.6232718825340271\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ThynoW8SqpOQ"
      },
      "source": [
        "**11.** Construisez, compilez, entraînez et évaluez le même réseau, cette fois avec l'augmentation des données :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RmKXE8SNqycx",
        "outputId": "d4862e60-22d1-409e-e998-d43983d92bd0"
      },
      "source": [
        "model = build_network(64, 64, 3, len(classes))\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='rmsprop',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "augmenter = ImageDataGenerator(horizontal_flip=True,\n",
        "                               rotation_range=30,\n",
        "                               width_shift_range=0.1,\n",
        "                               height_shift_range=0.1,\n",
        "                               shear_range=0.2,\n",
        "                               zoom_range=0.2,\n",
        "                               fill_mode='nearest')\n",
        "train_generator = augmenter.flow(X_train, y_train, BATCH_SIZE)\n",
        "history = model.fit(train_generator,\n",
        "                    steps_per_epoch=len(X_train) // BATCH_SIZE,\n",
        "                    validation_data=(X_test, y_test),\n",
        "                    epochs=EPOCHS)\n",
        "result = model.evaluate(X_test, y_test)\n",
        "print(f'Test accuracy: {result[1]}')\n",
        "plot_model_history(history, 'accuracy', 'augmented')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "108/108 [==============================] - 14s 111ms/step - loss: 3.3722 - accuracy: 0.3157 - val_loss: 5.1492 - val_accuracy: 0.1008\n",
            "Epoch 2/40\n",
            "108/108 [==============================] - 12s 113ms/step - loss: 2.6713 - accuracy: 0.4105 - val_loss: 4.4853 - val_accuracy: 0.1394\n",
            "Epoch 3/40\n",
            "108/108 [==============================] - 12s 109ms/step - loss: 2.3089 - accuracy: 0.4687 - val_loss: 3.5878 - val_accuracy: 0.2373\n",
            "Epoch 4/40\n",
            "108/108 [==============================] - 12s 114ms/step - loss: 2.0770 - accuracy: 0.5104 - val_loss: 2.3261 - val_accuracy: 0.4758\n",
            "Epoch 5/40\n",
            "108/108 [==============================] - 12s 113ms/step - loss: 1.9038 - accuracy: 0.5389 - val_loss: 1.9020 - val_accuracy: 0.5622\n",
            "Epoch 6/40\n",
            "108/108 [==============================] - 12s 113ms/step - loss: 1.8023 - accuracy: 0.5610 - val_loss: 4.0087 - val_accuracy: 0.4562\n",
            "Epoch 7/40\n",
            "108/108 [==============================] - 12s 111ms/step - loss: 1.7287 - accuracy: 0.5764 - val_loss: 1.9902 - val_accuracy: 0.5616\n",
            "Epoch 8/40\n",
            "108/108 [==============================] - 12s 112ms/step - loss: 1.6028 - accuracy: 0.6006 - val_loss: 1.9002 - val_accuracy: 0.5864\n",
            "Epoch 9/40\n",
            "108/108 [==============================] - 12s 111ms/step - loss: 1.5213 - accuracy: 0.6209 - val_loss: 1.6559 - val_accuracy: 0.6043\n",
            "Epoch 10/40\n",
            "108/108 [==============================] - 12s 110ms/step - loss: 1.4664 - accuracy: 0.6248 - val_loss: 1.7274 - val_accuracy: 0.6066\n",
            "Epoch 11/40\n",
            "108/108 [==============================] - 12s 110ms/step - loss: 1.3866 - accuracy: 0.6448 - val_loss: 1.6444 - val_accuracy: 0.6077\n",
            "Epoch 12/40\n",
            "108/108 [==============================] - 12s 110ms/step - loss: 1.3259 - accuracy: 0.6584 - val_loss: 1.7655 - val_accuracy: 0.5858\n",
            "Epoch 13/40\n",
            "108/108 [==============================] - 12s 110ms/step - loss: 1.2572 - accuracy: 0.6772 - val_loss: 1.8070 - val_accuracy: 0.5818\n",
            "Epoch 14/40\n",
            "108/108 [==============================] - 12s 115ms/step - loss: 1.2092 - accuracy: 0.6829 - val_loss: 1.6537 - val_accuracy: 0.6129\n",
            "Epoch 15/40\n",
            "108/108 [==============================] - 12s 110ms/step - loss: 1.1780 - accuracy: 0.6929 - val_loss: 1.7146 - val_accuracy: 0.6048\n",
            "Epoch 16/40\n",
            "108/108 [==============================] - 12s 110ms/step - loss: 1.0850 - accuracy: 0.7163 - val_loss: 1.5675 - val_accuracy: 0.6388\n",
            "Epoch 17/40\n",
            "108/108 [==============================] - 12s 113ms/step - loss: 1.0638 - accuracy: 0.7112 - val_loss: 1.6618 - val_accuracy: 0.6210\n",
            "Epoch 18/40\n",
            "108/108 [==============================] - 12s 109ms/step - loss: 1.0021 - accuracy: 0.7310 - val_loss: 1.6315 - val_accuracy: 0.6262\n",
            "Epoch 19/40\n",
            "108/108 [==============================] - 12s 111ms/step - loss: 0.9892 - accuracy: 0.7371 - val_loss: 1.7667 - val_accuracy: 0.5997\n",
            "Epoch 20/40\n",
            "108/108 [==============================] - 12s 109ms/step - loss: 0.9457 - accuracy: 0.7429 - val_loss: 1.6814 - val_accuracy: 0.6164\n",
            "Epoch 21/40\n",
            "108/108 [==============================] - 12s 107ms/step - loss: 0.9071 - accuracy: 0.7570 - val_loss: 1.7215 - val_accuracy: 0.6112\n",
            "Epoch 22/40\n",
            "108/108 [==============================] - 12s 109ms/step - loss: 0.9010 - accuracy: 0.7551 - val_loss: 1.4886 - val_accuracy: 0.6550\n",
            "Epoch 23/40\n",
            "108/108 [==============================] - 12s 108ms/step - loss: 0.8585 - accuracy: 0.7679 - val_loss: 1.7427 - val_accuracy: 0.6262\n",
            "Epoch 24/40\n",
            "108/108 [==============================] - 12s 109ms/step - loss: 0.8455 - accuracy: 0.7689 - val_loss: 1.7894 - val_accuracy: 0.6302\n",
            "Epoch 25/40\n",
            "108/108 [==============================] - 12s 108ms/step - loss: 0.8049 - accuracy: 0.7790 - val_loss: 1.5928 - val_accuracy: 0.6446\n",
            "Epoch 26/40\n",
            "108/108 [==============================] - 12s 107ms/step - loss: 0.7808 - accuracy: 0.7880 - val_loss: 1.7543 - val_accuracy: 0.6146\n",
            "Epoch 27/40\n",
            "108/108 [==============================] - 12s 109ms/step - loss: 0.7571 - accuracy: 0.7896 - val_loss: 1.6214 - val_accuracy: 0.6342\n",
            "Epoch 28/40\n",
            "108/108 [==============================] - 12s 111ms/step - loss: 0.7258 - accuracy: 0.7992 - val_loss: 1.6707 - val_accuracy: 0.6446\n",
            "Epoch 29/40\n",
            "108/108 [==============================] - 12s 111ms/step - loss: 0.7118 - accuracy: 0.7983 - val_loss: 1.8152 - val_accuracy: 0.6250\n",
            "Epoch 30/40\n",
            "108/108 [==============================] - 12s 114ms/step - loss: 0.6937 - accuracy: 0.8053 - val_loss: 1.7072 - val_accuracy: 0.6394\n",
            "Epoch 31/40\n",
            "108/108 [==============================] - 12s 113ms/step - loss: 0.6788 - accuracy: 0.8115 - val_loss: 1.7745 - val_accuracy: 0.6400\n",
            "Epoch 32/40\n",
            "108/108 [==============================] - 12s 113ms/step - loss: 0.6562 - accuracy: 0.8159 - val_loss: 1.6733 - val_accuracy: 0.6411\n",
            "Epoch 33/40\n",
            "108/108 [==============================] - 12s 113ms/step - loss: 0.6442 - accuracy: 0.8181 - val_loss: 1.7296 - val_accuracy: 0.6279\n",
            "Epoch 34/40\n",
            "108/108 [==============================] - 12s 111ms/step - loss: 0.6271 - accuracy: 0.8270 - val_loss: 1.7808 - val_accuracy: 0.6325\n",
            "Epoch 35/40\n",
            "108/108 [==============================] - 12s 111ms/step - loss: 0.6039 - accuracy: 0.8339 - val_loss: 1.8273 - val_accuracy: 0.6313\n",
            "Epoch 36/40\n",
            "108/108 [==============================] - 12s 111ms/step - loss: 0.5941 - accuracy: 0.8374 - val_loss: 1.9460 - val_accuracy: 0.6129\n",
            "Epoch 37/40\n",
            "108/108 [==============================] - 12s 111ms/step - loss: 0.5680 - accuracy: 0.8424 - val_loss: 1.7095 - val_accuracy: 0.6498\n",
            "Epoch 38/40\n",
            "108/108 [==============================] - 12s 110ms/step - loss: 0.5599 - accuracy: 0.8437 - val_loss: 1.8490 - val_accuracy: 0.6359\n",
            "Epoch 39/40\n",
            "108/108 [==============================] - 12s 110ms/step - loss: 0.5756 - accuracy: 0.8367 - val_loss: 1.8796 - val_accuracy: 0.6354\n",
            "Epoch 40/40\n",
            "108/108 [==============================] - 12s 110ms/step - loss: 0.5590 - accuracy: 0.8414 - val_loss: 1.6599 - val_accuracy: 0.6642\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 1.6599 - accuracy: 0.6642\n",
            "Test accuracy: 0.664170503616333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QvzH-8-prPPW"
      },
      "source": [
        "En comparant les étapes 10 et 11, nous observons un gain notable de performances en utilisant l'augmentation de données. Comprenons mieux ce que nous avons fait dans la section suivante"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zl1JUX6hrasZ"
      },
      "source": [
        "Dans cette recette, nous avons implémenté une version réduite de VGG sur le jeu de données Caltech 101 difficile. Tout d'abord, nous avons formé un réseau uniquement sur les données d'origine, puis en utilisant l'augmentation des données. Le premier réseau (voir étape 10) a obtenu un niveau de précision sur le jeu de test de 62,3 % et montre clairement des signes de dépassement, car l'écart qui sépare les courbes de précision d'apprentissage et de validation est très large. D'autre part, en appliquant une série de perturbations aléatoires, via ImageDataGenerator(), telles que des basculements horizontaux, des rotations, des changements de largeur et de hauteur, entre autres (voir l'étape 11), nous avons augmenté la précision sur l'ensemble de test à 66,4 %. De plus, l'écart entre les courbes de précision d'apprentissage et de validation est beaucoup plus faible cette fois, ce qui suggère un effet de régularisation résultant de l'application de l'augmentation des données."
      ]
    }
  ]
}