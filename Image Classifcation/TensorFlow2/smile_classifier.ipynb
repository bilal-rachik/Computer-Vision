{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "smile_classifier.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kmUxJ8Fsy4u1"
      },
      "source": [
        "# Créer un classificateur binaire pour détecter les sourires\n",
        "\n",
        "Dans sa forme la plus élémentaire, la classification d'images consiste à discerner entre deux classes, ou à signaler la présence ou l'absence d'un trait. Dans cette recette, nous allons implémenter un classificateur binaire qui nous dit si une personne sur une photo sourit. Commençons, voulez-vous ?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7j_mtctzZ5f"
      },
      "source": [
        "Vous devrez installer Pillow, ce qui est très facile avec pip"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jNgkbbGgzotD"
      },
      "source": [
        "! pip install Pillow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PQGkjrk-znuC"
      },
      "source": [
        "Nous utiliserons l'ensemble de données SMILEs, situé ici : https://github.com/hromi/SMILEsmileD. Clonez ou téléchargez une version zippée du référentiel à l'emplacement de votre choix. Dans cette recette."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8v2uREI0Zuj"
      },
      "source": [
        "#! wget https://github.com/hromi/SMILEsmileD/archive/refs/heads/master.zip\n",
        "#! unzip master.zip"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zzj3CiYo1Z4a"
      },
      "source": [
        "Suivez ces étapes pour former un classificateur à partir de zéro sur l'ensemble de données SMILEs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eWDOmNEX1ilp"
      },
      "source": [
        "1. Importez tous les packages nécessaires :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aMvXQWT5zm0U"
      },
      "source": [
        "import os\n",
        "import pathlib\n",
        "\n",
        "import glob\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.preprocessing.image import *"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NaELg5uf103i"
      },
      "source": [
        "2. Dénissez une fonction pour charger les images et les étiquettes à partir d'une liste de chemins:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqzCOQ5x2Atu"
      },
      "source": [
        "def load_images_and_labels(image_paths):\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    for image_path in image_paths:\n",
        "        image = load_img(image_path, target_size=(32, 32),\n",
        "                         color_mode='grayscale')\n",
        "        image = img_to_array(image)\n",
        "\n",
        "        label = image_path.split(os.path.sep)[-2]\n",
        "        label = 'positive' in label\n",
        "        label = float(label)\n",
        "\n",
        "        images.append(image)\n",
        "        labels.append(label)\n",
        "\n",
        "    return np.array(images), np.array(labels)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LVMcRfLT2e-Y"
      },
      "source": [
        "Notez que nous chargeons les images en niveaux de gris, et nous encodons les étiquettes en vérifiant si le mot positif est dans le chemin du fichier de l'image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbaMzqM12px5"
      },
      "source": [
        "3. Déﬁnissez une fonction pour construire le réseau de neurones. La structure de ce modèle est basée sur LeNet:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dCvA1M6H29YZ"
      },
      "source": [
        "def build_network():\n",
        "    input_layer = Input(shape=(32, 32, 1))\n",
        "    x = Conv2D(filters=20,\n",
        "               kernel_size=(5, 5),\n",
        "               padding='same',\n",
        "               strides=(1, 1))(input_layer)\n",
        "    x = ELU()(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = MaxPooling2D(pool_size=(2, 2),\n",
        "                     strides=(2, 2))(x)\n",
        "    x = Dropout(0.4)(x)\n",
        "\n",
        "    x = Conv2D(filters=50,\n",
        "               kernel_size=(5, 5),\n",
        "               padding='same',\n",
        "               strides=(1, 1))(x)\n",
        "    x = ELU()(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = MaxPooling2D(pool_size=(2, 2),\n",
        "                     strides=(2, 2))(x)\n",
        "    x = Dropout(0.4)(x)\n",
        "\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(units=500)(x)\n",
        "    x = ELU()(x)\n",
        "    x = Dropout(0.4)(x)\n",
        "\n",
        "    output = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "    model = Model(inputs=input_layer, outputs=output)\n",
        "    return model"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NVLwkhxj3TDv"
      },
      "source": [
        "Parce qu'il s'agit d'un problème de classification binaire, un seul neurone activé par le sigmoïde suffit dans la couche de sortie"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xz_gNVs-3eVP"
      },
      "source": [
        "4. Chargez les chemins d'images dans une liste :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e21RN3Z73lTx"
      },
      "source": [
        "files_pattern = (pathlib.Path('/content/') /\n",
        "                 'SMILEsmileD-master' / 'SMILEs' / '*' / '*' /'*.jpg')\n",
        "files_pattern = str(files_pattern)\n",
        "dataset_paths = [*glob.glob(files_pattern)]"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jzkm78a85HBD"
      },
      "source": [
        "5. Utilisez la fonction load_images_and_labels() dénie précédemment pour charger l'ensemble de données en mémoire :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rN2BI1pi5LSe"
      },
      "source": [
        "X, y = load_images_and_labels(dataset_paths)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sKBxDH3r5ZIC"
      },
      "source": [
        "\n",
        "6. Normalisez les images et calculez le nombre d'exemples positifs, négatifs dans l'ensemble de données :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JRZmEUUD5nQ0",
        "outputId": "f61ea6c1-a7ee-4735-cee1-e1ef186d7dd2"
      },
      "source": [
        "X /= 255.0\n",
        "total = len(y)\n",
        "total_positive = np.sum(y)\n",
        "total_negative = total - total_positive\n",
        "print(f'Total images: {total}')\n",
        "print(f'Smile images: {total_positive}')\n",
        "print(f'Non-smile images: {total_negative}')"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total images: 13165\n",
            "Smile images: 3690.0\n",
            "Non-smile images: 9475.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pPQ7fAkH5ztt"
      },
      "source": [
        "7. Créez des sous-ensembles d'apprentissage, de test et de validation des données :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-FGgKCyY59YO"
      },
      "source": [
        "(X_train, X_test,\n",
        " y_train, y_test) = train_test_split(X, y,\n",
        "                                     test_size=0.2,\n",
        "                                     stratify=y,\n",
        "                                     random_state=999)\n",
        "(X_train, X_val,\n",
        " y_train, y_val) = train_test_split(X_train, y_train,\n",
        "                                    test_size=0.2,\n",
        "                                    stratify=y_train,\n",
        "                                    random_state=999)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4SRpvwDt6UO_"
      },
      "source": [
        "\n",
        "8. Instanciez le modèle et compilez-le :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFTeel476XXJ"
      },
      "source": [
        "model = build_network()\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='rmsprop',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQBcEZhr6i1h"
      },
      "source": [
        "9. Entraînez le modèle. Étant donné que l'ensemble de données est déséquilibré, nous attribuons à chaque classe des poids proportionnels au nombre d'images positives et négatives dans l'ensemble de données :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GL3XNgpS6iIZ",
        "outputId": "7770fb2e-ea44-4814-fb24-cfaff63d2df5"
      },
      "source": [
        "BATCH_SIZE = 32\n",
        "EPOCHS = 20\n",
        "model.fit(X_train, y_train,\n",
        "          validation_data=(X_val, y_val),\n",
        "          epochs=EPOCHS,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          class_weight={\n",
        "              1.0: total / total_positive,\n",
        "              0.0: total / total_negative\n",
        "          })"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "264/264 [==============================] - 29s 103ms/step - loss: 1.9446 - accuracy: 0.7469 - val_loss: 0.5208 - val_accuracy: 0.8011\n",
            "Epoch 2/20\n",
            "264/264 [==============================] - 27s 103ms/step - loss: 1.0119 - accuracy: 0.8218 - val_loss: 0.2957 - val_accuracy: 0.8956\n",
            "Epoch 3/20\n",
            "264/264 [==============================] - 27s 103ms/step - loss: 0.8430 - accuracy: 0.8375 - val_loss: 0.2930 - val_accuracy: 0.8899\n",
            "Epoch 4/20\n",
            "264/264 [==============================] - 27s 103ms/step - loss: 0.7616 - accuracy: 0.8536 - val_loss: 0.2516 - val_accuracy: 0.8989\n",
            "Epoch 5/20\n",
            "264/264 [==============================] - 27s 103ms/step - loss: 0.6666 - accuracy: 0.8675 - val_loss: 0.3665 - val_accuracy: 0.8334\n",
            "Epoch 6/20\n",
            "264/264 [==============================] - 27s 103ms/step - loss: 0.6219 - accuracy: 0.8818 - val_loss: 0.3400 - val_accuracy: 0.8614\n",
            "Epoch 7/20\n",
            "264/264 [==============================] - 27s 103ms/step - loss: 0.6050 - accuracy: 0.8817 - val_loss: 0.4401 - val_accuracy: 0.7860\n",
            "Epoch 8/20\n",
            "264/264 [==============================] - 27s 103ms/step - loss: 0.5766 - accuracy: 0.8909 - val_loss: 0.2266 - val_accuracy: 0.9089\n",
            "Epoch 9/20\n",
            "264/264 [==============================] - 27s 103ms/step - loss: 0.5484 - accuracy: 0.8948 - val_loss: 0.4172 - val_accuracy: 0.8253\n",
            "Epoch 10/20\n",
            "264/264 [==============================] - 27s 104ms/step - loss: 0.5281 - accuracy: 0.9029 - val_loss: 0.5013 - val_accuracy: 0.7869\n",
            "Epoch 11/20\n",
            "264/264 [==============================] - 27s 103ms/step - loss: 0.5142 - accuracy: 0.9002 - val_loss: 0.3009 - val_accuracy: 0.9075\n",
            "Epoch 12/20\n",
            "264/264 [==============================] - 27s 103ms/step - loss: 0.5018 - accuracy: 0.9078 - val_loss: 0.2093 - val_accuracy: 0.9131\n",
            "Epoch 13/20\n",
            "264/264 [==============================] - 27s 103ms/step - loss: 0.4665 - accuracy: 0.9129 - val_loss: 0.2616 - val_accuracy: 0.8932\n",
            "Epoch 14/20\n",
            "264/264 [==============================] - 27s 103ms/step - loss: 0.4435 - accuracy: 0.9145 - val_loss: 0.5716 - val_accuracy: 0.8728\n",
            "Epoch 15/20\n",
            "264/264 [==============================] - 27s 103ms/step - loss: 0.4474 - accuracy: 0.9154 - val_loss: 0.4396 - val_accuracy: 0.9084\n",
            "Epoch 16/20\n",
            "264/264 [==============================] - 27s 103ms/step - loss: 0.4377 - accuracy: 0.9208 - val_loss: 0.3649 - val_accuracy: 0.8671\n",
            "Epoch 17/20\n",
            "264/264 [==============================] - 27s 104ms/step - loss: 0.4078 - accuracy: 0.9270 - val_loss: 0.2366 - val_accuracy: 0.9207\n",
            "Epoch 18/20\n",
            "264/264 [==============================] - 27s 103ms/step - loss: 0.4105 - accuracy: 0.9230 - val_loss: 0.2905 - val_accuracy: 0.8813\n",
            "Epoch 19/20\n",
            "264/264 [==============================] - 27s 104ms/step - loss: 0.3981 - accuracy: 0.9258 - val_loss: 0.4574 - val_accuracy: 0.8794\n",
            "Epoch 20/20\n",
            "264/264 [==============================] - 27s 104ms/step - loss: 0.4000 - accuracy: 0.9271 - val_loss: 0.2953 - val_accuracy: 0.8994\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4816fa3b10>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lsDLwCO665uB"
      },
      "source": [
        "10. Évaluez le modèle sur l'ensemble de test :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ueqU8eOC69Np",
        "outputId": "f9f63a7b-f81f-44a1-dd47-9995cf9242c6"
      },
      "source": [
        "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "print(f'Loss: {test_loss}, accuracy: {test_accuracy}')"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "83/83 [==============================] - 2s 27ms/step - loss: 0.2938 - accuracy: 0.9028\n",
            "Loss: 0.29380494356155396, accuracy: 0.9027724862098694\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFX3F0ZW7JYq"
      },
      "source": [
        "Après 20 époques, le réseau devrait obtenir une précision d'environ 90 % sur l'ensemble de test. Dans la section suivante"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ShZg2Icz7UwZ"
      },
      "source": [
        "Nous venons de former un réseau pour déterminer si une personne sourit ou non sur une photo. Notre première grande tâche a été de prendre les images de l'ensemble de données et de les charger dans un format adapté à notre réseau de neurones. Plus précisément, la fonction load_image_and_labels() est chargée de charger une image en niveaux de gris, de la redimensionner en 32x32x1, puis de la convertir en un tableau numpy. Pour extraire l'étiquette, nous avons regardé le dossier contenant de chaque image : s'il contenait le mot positif, nous avons codé l'étiquette comme 1 ; sinon, nous l'avons encodé en 0 (une astuce que nous avons utilisée ici consistait à convertir un booléen en flottant, comme ceci : float(label)).\n",
        "\n",
        "Ensuite, nous avons construit le réseau de neurones, qui s'inspire de l'architecture LeNet. Le plus gros point à retenir ici est que, parce qu'il s'agit d'un problème de classification binaire, nous pouvons utiliser un seul neurone activé par le sigmoïde pour discerner entre les deux classes.\n",
        "\n",
        "Nous avons ensuite pris 20 % des images pour constituer notre ensemble de test, et sur les 80 % restants, nous avons pris 20 % supplémentaires pour créer notre ensemble de validation. Avec ces trois sous-ensembles, nous avons procédé à la formation du réseau sur 20 époques, en utilisant binary_crossentropy comme fonction de perte et rmsprop comme optimiseur.\n",
        "\n",
        "Pour tenir compte du déséquilibre dans l'ensemble de données (sur les 13 165 images, seules 3 690 contiennent des personnes souriantes, tandis que les 9 475 autres ne le font pas), nous avons passé un dictionnaire class_weight où nous avons attribué un poids inversement proportionnel au nombre d'instances de chaque classe dans l'ensemble de données, forçant efectivement le modèle à accorder plus d'attention à la classe 1.0, qui correspond à smile.\n",
        "\n",
        "Enfin, nous avons atteint une précision d'environ 90,5% sur l'ensemble de test"
      ]
    }
  ]
}