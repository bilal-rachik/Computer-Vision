{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Introduction_CNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0oTq_05-O3MZ"
      },
      "source": [
        "# Convolutional Neural Networks\n",
        "\n",
        ". Dans ce chapitre, nous explorerons les différents concepts de CNN, qui sont principalement utilisés pour résoudre des problèmes de vision par ordinateur (c'est-à-dire le traitement d'images).\n",
        "\n",
        "Même si tous les domaines de réseaux de neurones sont populaires de nos jours, les CNN sont probablement les plus populaires de toutes les architectures de réseaux de neurones. C'est principalement parce que, bien qu'ils fonctionnent dans de nombreux domaines, ils sont particulièrement bons pour traiter les images, et les progrès technologiques ont permis la collecte et le stockage de grandes quantités d'images, ce qui permet de relever une grande variété de défis d'aujourd'hui en utilisant images comme données d'entrée.\n",
        "\n",
        "De la classification d'images à la détection d'objets, les CNN sont utilisés pour diagnostiquer les patients atteints de cancer et détecter les fraudes dans les systèmes, ainsi que pour construire des véhicules autonomes bien pensés qui révolutionneront l'avenir.\n",
        "\n",
        "Cet article se concentrera sur l'explication des raisons pour lesquelles les CNN surpassent les autres architectures lorsqu'il s'agit d'images, ainsi que sur l'explication plus détaillée des éléments constitutifs de leur architecture. Il couvrira la structure de codage principale pour construire un CNN pour résoudre un problème de données de classification d'images.\n",
        "\n",
        "De plus, nous explorerons les concepts d'augmentation de données et de normalisation par lots, qui seront utilisés pour améliorer les performances du modèle. Le but ultime de ce chapitre est de comparer les résultats de trois approches diérentes afin d'aborder un problème de classification d'images à l'aide de CNN."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3zs-Sm8wZoEO"
      },
      "source": [
        "## Construire un CNN\n",
        "\n",
        "Les CNN sont l'architecture idéale pour traiter un problème de données d'image. ils sont généralement utilisés pour des tâches de classification d'images, même si leurs capacités s'étendent à d'autres domaines du traitement d'images. Ce article expliquera non seulement les raisons pour lesquelles les CNN sont si bons pour comprendre les images, mais identifiera également les différentes tâches qui peuvent être abordées, ainsi que quelques exemples d'applications réelles.\n",
        "\n",
        "De plus, cet article explorera les différents blocs de construction des CNN et leur application à l'aide de PyTorch pour finalement construire un modèle qui résout un problème de données en utilisant l'un des ensembles de données de PyTorch pour la classification d'images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oUyaPmfoadEG"
      },
      "source": [
        "### Pourquoi les CNN sont-ils utilisés pour le traitement d'images ?\n",
        "\n",
        "Une image est une matrice de pixels, alors pourquoi ne pas simplement aplatir la matrice en un vecteur et la traiter à l'aide d'une architecture de réseau de neurones traditionnelle ? La réponse est que, même avec l'image la plus simple, il existe des dépendances de pixels qui modifient la signification de l'image. Par exemple, la représentation d'un œil de chat, d'un pneu de voiture ou encore du bord d'un objet est construite à partir de plusieurs pixels disposés d'une certaine manière. Si on aplatit l'image, ces dépendances sont perdues, de même que la précision d'un modèle traditionnel.\n",
        "\n",
        "Un CNN est capable de capturer les dépendances spatiales des images car il les traite comme des matrices et analyse des morceaux entiers d'une image à la fois, en fonction de la taille du filtre. Par exemple, une couche convolutive utilisant un filtre de taille 3 x 3 analysera 9 pixels à la fois jusqu'à couvrir toute l'image.\n",
        "\n",
        "Chaque morceau de l'image se voit attribuer un ensemble de paramètres (poids et biais) qui feront référence à la pertinence de cet ensemble de pixels pour l'ensemble de l'image, en fonction du filtre utilisé. Cela signifie qu'un filtre de bord vertical attribuera des poids plus importants aux morceaux de l'image qui contiennent un bord vertical. Selon cela, en réduisant le nombre de paramètres et en analysant l'image en morceaux, les CNN sont capables de restituer une meilleure représentation de l'image.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWKF5tDwcvS-"
      },
      "source": [
        "### L'image en entrée\n",
        "\n",
        "Comme nous l'avons mentionné précédemment, les entrées typiques d'un CNN sont des images sous forme de matrices. Chaque valeur de la matrice représente un pixel dans l'image, où le nombre est déterminé par l'intensité de la couleur, avec des valeurs allant de 0 à 255.\n",
        "\n",
        "Dans les images en niveaux de gris, les pixels blancs sont représentés par le nombre 255 et les pixels noirs par le nombre 0. Les pixels gris sont n'importe quel nombre entre les deux, en fonction de l'intensité de la couleur ; plus le gris est clair, plus le nombre est proche de 255.\n",
        "\n",
        "Les images colorées sont généralement représentées à l'aide du système RGB, qui représente chaque couleur comme la combinaison du rouge, du vert et du bleu. Ici, chaque pixel aura trois dimensions, une pour chaque couleur. Les valeurs de chaque dimension vont de 0 à 255. Ici, plus la couleur est intense, plus le nombre est proche de 255.\n",
        "\n",
        "D'après le paragraphe précédent, la matrice d'une image donnée est tridimensionnelle. Ici, la première dimension fait référence à la hauteur de l'image (en nombre de pixels), la deuxième dimension fait référence à la largeur de l'image (en nombre de pixels), et la troisième dimension est connue sous le nom de canal et fait référence à la palette de couleurs de l'image.\n",
        "\n",
        "Le nombre de canaux pour les images colorées est de trois (un canal pour chaque couleur dans le système RVB). En revanche, les images en niveaux de gris n'ont qu'un seul canal.\n",
        "\n",
        "Contrairement aux données textuelles, les images qui sont introduites dans les CNN ne nécessitent pas beaucoup de prétraitement. Les images sont généralement alimentées telles quelles, les modifications les plus courantes étant les suivantes:\n",
        "* Normaliser les valeurs de pixels afin d'accélérer le processus d'apprentissage et d'améliorer les performances.\n",
        "* Réduire la taille des images (c'est-à-dire réduire leur largeur et leur longueur) pour accélérer le processus d'apprentissage.\n",
        "\n",
        "La façon la plus simple de normaliser les entrées est de prendre la valeur de chaque pixel et de la diviser par 255 pour obtenir des valeurs comprises entre 0 et 1. Néanmoins, différentes méthodologies sont utilisées pour normaliser une image, comme la moyenne. technique de centrage. La décision de choisir l'un ou l'autre, Cependant, lorsque vous utilisez des modèles pré-entraînés, il est fortement recommandé d'utiliser la même technique que celle que vous avez utilisée pour entraîner le modèle la première fois. Cette information est souvent disponible dans la documentation du modèle pré-entraîné.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2WzyoJDgts3"
      },
      "source": [
        "## Les blocs de construction des CNN\n",
        "\n",
        "Un réseau convolutif profond est un réseau qui prend une image en entrée et la fait passer à travers une série de couches convolutives avec des filtres, des Pooling et des couches entièrement connectées (FC) pour finalement appliquer une fonction d'activation softmax qui classe l'image en une étiquette de classe. Cette forme de classification, comme pour les ANN, est réalisée en calculant la probabilité que l'image appartienne à chacune des étiquettes de classe en attribuant à chaque étiquette de classe une valeur comprise entre zéro et un. L'étiquette de classe avec la probabilité la plus élevée est celle qui est sélectionnée comme prédiction finale pour cette image.\n",
        "\n",
        "Ce qui suit est une explication détaillée de chacune de ces couches, ainsi que des exemples de code sur la façon de définir de telles couches dans PyTorch.\n",
        "\n",
        "### Couches convolutives\n",
        "\n",
        "C'est la première étape de l'extraction des caractéristiques d'une image. L'objectif est de maintenir la relation entre les pixels voisins en apprenant les caractéristiques sur de petites sections de l'image.\n",
        "\n",
        "Une opération mathématique se produit dans cette couche, où deux entrées sont données (l'image et le filtre) et une sortie est obtenue. Comme nous l'avons expliqué précédemment, cette opération consiste à convoluer le filtre et une section de l'image de même taille que le filtre. Cette opération est répétée pour toutes les sous-sections de l'image.\n",
        "\n",
        "La matrice résultante aura une forme qui dépend des formes des entrées, où une matrice image de taille (h x w x c) et un filtre de taille ($f_h$ x $f_w$ x c) sortiront une matrice selon l'équation suivante:\n",
        "\n",
        "$$ output\\ height = h-f_h+1$$\n",
        "$$output\\ width = w- f_w+1$$\n",
        "$$output\\ depth = 1$$\n",
        "\n",
        "Ici, h fait référence à la hauteur de l'image d'entrée, w à la largeur, c à la profondeur (également appelée canaux) et $f_h$ et $f_w$ sont des valeurs définies par l'utilisateur concernant la taille du filtre\n",
        "\n",
        "Le diagramme suivant illustre cette conversion de dimension sous forme de matrices, où les matrices à gauche représentent une image colorée, les matrices au centre représentent un seul filtre qui est appliqué à tous les canaux de l'image, et la matrice à la droite est la sortie du calcul de l'image et du filtre\n",
        "\n",
        "<img src='http://media5.datahacker.rs/2018/11/06_04.png' width=700px>\n",
        "\n",
        "Il est important de mentionner que dans une même couche convolutive, plusieurs filtres peuvent être appliqués sur la même image, tous de même forme. Compte tenu de cela, la forme de sortie d'une couche convolutive qui applique deux filtres à son entrée, en termes de profondeur, est égale à deux, comme le montre le schéma suivant:\n",
        "\n",
        "<img src='https://miro.medium.com/max/1400/1*DmAwcMCcHqZdF62J0hNWlQ.png' width=500px>\n",
        "\n",
        "Chacun de ces filtres effectuera une opération différente afin de découvrir les différentes caractéristiques d'une image. Par exemple, dans une seule couche convolutive avec deux filtres, ces opérations pourraient être la détection de bords verticaux et la détection de bords horizontaux. Au fur et à mesure que le réseau grandit en termes de nombre de couches, les filtres effectueront des opérations plus complexes qui utilisent des caractéristiques précédemment détectées, par exemple, la détection du contour d'une personne en utilisant les entrées des détecteurs de bord.\n",
        "\n",
        "Les filtres augmentent généralement dans chaque couche. Cela signifie que, alors que la première couche convolutive a 8 filtres, il est courant de créer la deuxième couche convolutive pour qu'elle ait le double de ce nombre (16), la troisième pour qu'elle ait à nouveau le double de ce nombre (32) ..etc\n",
        "\n",
        "Cependant, il est important de mentionner que, dans PyTorch, comme dans de nombreux autres frameworks, vous ne devez dénir que le nombre de filtres à utiliser et non le type de filtres (par exemple, un détecteur de bord vertical). Chaque configuration de filtre (les nombres qu'elle contient pour détecter une caractéristique spécifique) fait partie des variables du système.\n",
        "\n",
        "Il y a deux concepts supplémentaires à introduire au sujet des couches convolutives, qui sont les suivants.\n",
        "\n",
        "### Padding\n",
        "\n",
        "Le paramètre de Padding, comme son nom l'indique, remplit l'image avec des zéros. Cela signifie qu'il ajoute des pixels supplémentaires (qui sont remplis de zéros) de chaque côté de l'image. Le diagramme suivant montre un exemple d'une image qui a été remplie d'un de chaque côté.\n",
        "\n",
        "https://images.deepai.org/glossary-terms/5361a0e82d3941e58903b90f64e71491/download.png\n",
        "\n",
        "<img src='https://images.deepai.org/glossary-terms/5361a0e82d3941e58903b90f64e71491/download.png' width=300px>\n",
        "\n",
        "Ceci est utilisé pour maintenir la forme de la matrice d'entrée une fois qu'elle est passée à travers le filtre. En effet, en particulier dans les deux premières couches, l'objectif devrait être de préserver autant d'informations que possible de l'entrée d'origine afin d'en extraire le plus de fonctionnalités.\n",
        "\n",
        "Pour mieux comprendre le concept de Padding, envisagez le scénario suivant. L'application d'un filtre 3 x 3 à une image colorée de forme 32 x 32 x 3 produirait une matrice de forme 30 x 30 x 1. Cela signifie que l'entrée pour la couche suivante a rétréci. Cependant, en ajoutant un padding de 1 à l'image d'entrée, la forme de l'entrée est modifiée en 34 x 34 x 3, ce qui donne une sortie de 32 x 32 x 1 en utilisant le même filtre.\n",
        "\n",
        "L'équation suivante peut être utilisée pour calculer la largeur de sortie lors de l'utilisation du padding\n",
        "\n",
        "$$ output\\ width = W - F +2*P+1$$\n",
        "\n",
        "Ici, $W$ fait référence à la largeur de la matrice d'entrée, $F$ à la largeur du filtre et $P$ au padding. La même équation peut être adaptée pour calculer la hauteur de la sortie.\n",
        "\n",
        "Pour obtenir une matrice de sortie de forme égale à l'entrée, utilisez l'équation suivante pour calculer la valeur du padding (considérant que le stride, que nous définirons dans la section suivante, est égale à un)\n",
        "\n",
        "$$ P = \\frac{F-1}{2}$$\n",
        "\n",
        "Gardez à l'esprit que le nombre de canaux de sortie (profondeur) sera toujours égal au nombre de filtres qui ont été appliqués à l'entrée.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4LkGFzRWrTQ3"
      },
      "source": [
        "## Stride\n",
        "\n",
        "Ce paramètre fait référence au nombre de pixels que le filtre déplacera sur la matrice d'entrée, à la fois horizontalement et verticalement. Comme nous l'avons vu jusqu'à présent, le filtre passe par le coin supérieur gauche de l'image, puis il se déplace vers la droite d'un pixel, et ainsi de suite jusqu'à ce qu'il ait parcouru toutes les sections de l'image verticalement et horizontalement . Cet exemple est celui d'une couche convolutive avec une stride égale à un, qui est la configuration par défaut pour ce paramètre.\n",
        "\n",
        "Lorsque le stride est égale à deux, le décalage serait de deux pixels à la place, comme le montre le diagramme suivant:\n",
        "\n",
        "<img src='https://indoml.files.wordpress.com/2018/03/stride.png?w=736' width=600px>\n",
        "\n",
        "Comme on peut le voir, l'opération initiale se produit dans le coin supérieur gauche ; puis, en décalant deux pixels vers la droite, le deuxième calcul se produit dans le coin supérieur droit. Ensuite, le calcul décale deux pixels vers le bas pour effectuer les calculs sur le coin inférieur gauche, et, finalement, en décalant à nouveau deux pixels vers la droite, le calcul final se produit dans le coin inférieur droit.\n",
        "\n",
        "L'équation suivante peut être utilisée pour calculer la largeur de sortie lors de l'utilisation de Stride\n",
        "\n",
        "$$ output\\ width = \\frac{ W - F}{S}+1$$\n",
        "\n",
        "Ici, $W$ fait référence à la largeur de la matrice d'entrée, $F$ à la largeur du filtre et $S$ à le stride. La même équation peut être adaptée pour calculer la hauteur de la sortie.\n",
        "\n",
        "Une fois ces paramètres introduits, l'équation finale pour calculer la forme de sortie (largeur et hauteur) de la matrice dérivée d'une couche convolutive est la suivante:\n",
        "\n",
        "$$ output\\ width = \\frac{ (W - F)+2*P}{S}+1$$\n",
        "\n",
        "Chaque fois que la valeur est flottante, elle doit être arrondie à l'inférieur. Cela signifie essentiellement que certaines zones de l'entrée sont ignorées et qu'aucune caractéristique n'en est extraite. Enfin, une fois que l'entrée a traversé tous les filtres, la sortie est envoyée à une fonction d'activation afin de briser la linéarité, similaire à le processus des réseaux de neurones traditionnels. Bien qu'il existe plusieurs fonctions d'activation qui peuvent être appliquées à cette étape, la préférée est la fonction ReLU car elle a montré des résultats exceptionnels dans les CNN. La sortie que nous avons obtenue ici devient l'entrée de la couche suivante, qui est généralement une couche de Pooling\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_XrpNmVtwzC"
      },
      "source": [
        "#### Exercice : Calcul de la forme de sortie d'une couche convolutive\n",
        "\n",
        "En utilisant les équations données, considérez les scénarios suivants et calculez la forme de la matrice de sortie\n",
        "\n",
        "* 1. Calculer la forme en sortie d'une matrice dérivée d'une couche convolutive avec une entrée de forme 64 x 64 x 3 et un filtre de forme 3 x 3 x 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rEJGZpoqu0FC",
        "outputId": "fa4cc48d-cf60-418b-81d6-84ab9b1d97a4"
      },
      "source": [
        "output_heidgth = 64 - 3 + 1\n",
        "output_width = 64 - 3 + 1\n",
        "output_depth = 1\n",
        "print('output_heidgth={}, output_width ={}, output_depth={}'.format(output_heidgth, output_width, output_depth) )"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "output_heidgth=62,output_width =62,output_depth=1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cbUS9zmcvVbB"
      },
      "source": [
        "* 2. Calculer la forme de sortie d'une matrice dérivée d'une couche convolutive avec une entrée de forme 32 x 32 x 3, 10 filtres de forme 5 x 5 x 3 et un padding de 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AArSQTNlvcWi",
        "outputId": "42c1a229-b8ab-4267-92f3-d19dd9fd3029"
      },
      "source": [
        "output_heidgth = 32- 5 +(2*2) + 1\n",
        "output_width = 32 - 3 + ( 2*2 )+ 1\n",
        "output_depth = 10\n",
        "print('output_heidgth={}, output_width ={}, output_depth={}'.format(output_heidgth, output_width, output_depth) )"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "output_heidgth=32, output_width =34, output_depth=10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K6_afx8ewB-x"
      },
      "source": [
        "* 3. Calculer la forme de sortie d'une matrice dérivée d'une couche convolutive avec une entrée de forme 128 x 128 x 1, cinq filtres de forme 5 x 5 x 1 et une stride de 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9unNaBk0wIwx",
        "outputId": "0b7ad1c2-89dd-4458-b66b-27636a219049"
      },
      "source": [
        "output_heidgth = (128- 5)/(3) + 1\n",
        "output_width = (128 - 5)/( 3 )+ 1\n",
        "output_depth = 5\n",
        "print('output_heidgth={}, output_width ={}, output_depth={}'.format(output_heidgth, output_width, output_depth) )"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "output_heidgth=42.0, output_width =42.0, output_depth=5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jcc-TAaRxV1-"
      },
      "source": [
        "* 4. Calculer la forme de sortie d'une matrice dérivée d'une couche convolutive avec une entrée de forme 64 x 64 x 1, un filtre de forme 8 x 8 x 1, un padding de 3 et une stride de 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MkUoZBy-xXuP",
        "outputId": "6c1bcc44-3193-4ef9-cdb7-630add6a84a0"
      },
      "source": [
        "output_heidgth = (64- 8+ 2*3)/(3) + 1\n",
        "output_width = (64 - 8+2*3)/( 3 )+ 1\n",
        "output_depth = 1\n",
        "print('output_heidgth={}, output_width ={}, output_depth={}'.format(output_heidgth, output_width, output_depth) )"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "output_heidgth=21.666666666666668, output_width =21.666666666666668, output_depth=1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86oAb5L4yKtz"
      },
      "source": [
        "Le codage d'une couche convolutive dans PyTorch est très simple. En utilisant des modules personnalisés, il ne nécessite que la création de la classe réseau. La classe doit contenir une méthode __init__ qui définit l'architecture du réseau (c'est-à-dire les couches du réseau) et une méthode directe qui définit les calculs à effectuer sur les informations lorsqu'elles passent à travers les couches, comme indiqué dans l'extrait de code suivant"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FbnOqoNVyazW"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class CNN_network(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(CNN_network, self).def__init__\n",
        "    self.conv1 = nn.Conv2d(3, 18, 3, 1,1)\n",
        "    \n",
        "  def forward(self, x):\n",
        "    x = F.relu(self.conv1(x))\n",
        "    return x"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hOzyYxAyzejR"
      },
      "source": [
        "Lors de la définition de la couche convolutive, les arguments passés de gauche à droite font référence aux canaux d'entrée, aux canaux de sortie (nombre de filtres), à la taille du noyau (taille du filtre), à ​​la stride et au padding.\n",
        "\n",
        "L'exemple précédent se compose d'une couche convolutive avec trois canaux d'entrée, 18 filtres, chacun de taille 3, et un stride et un padding égaux à 1\n",
        "\n",
        "Une autre approche valide, équivalente à l'exemple précédent, consiste en une combinaison de la syntaxe des modules personnalisés et de l'utilisation de conteneurs séquentiels, comme on peut le voir dans l'extrait de code suivant\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NhIVQhz70aZa"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class CNN_network(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(CNN_network, self).def__init__\n",
        "    self.conv1 = nn.Sequential(nn.Conv2d(3, 18, 3, 1,1), nn.ReLU())\n",
        "    \n",
        "  def forward(self, x):\n",
        "    x = self.conv1(x)\n",
        "    return x"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OsVuT6Mz0xV8"
      },
      "source": [
        "Ici, la définition des couches se produit à l'intérieur du conteneur séquentiel. Typiquement, un conteneur comprend une couche convolutive, une fonction d'activation et une couche de pooling. Un nouvel ensemble de couches est inclus dans un conteneur différent en dessous\n",
        "\n",
        "Dans l'exemple précédent, la couche convolutive et la couche d'activation sont définies à l'intérieur du conteneur séquentiel. Par conséquent, dans la méthode directe, il n'est pas nécessaire de faire passer la sortie de la couche convolutive à travers la fonction d'activation car elle a déjà été gérée à l'aide du conteneur"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LOq_QOrK1Wn6"
      },
      "source": [
        "## Pooling \n",
        "\n",
        "Classiquement, les couches de pooling sont la dernière partie de l'étape de sélection des caractéristiques, c'est pourquoi une couche de pooling peut principalement être trouvée après une couche convolutive. Comme nous l'avons expliqué dans les chapitres précédents, l'idée est d'extraire les informations les plus pertinentes des sous-sections de l'image. La taille de la couche de pooling est généralement est de tail 2 et le stride est égale à sa taille.\n",
        "\n",
        "Les couches de Pooling réduisent généralement de moitié la hauteur et la largeur de l'entrée. Ceci est important étant donné que, pour que les couches convolutives trouvent toutes les caractéristiques d'une image, plusieurs filtres doivent être utilisés, et la sortie de cette opération peut devenir trop grande, ce qui signifie qu'il y a de nombreux paramètres à prendre en compte. Les couches de pooling visent à réduire le nombre de paramètres dans le réseau en conservant les fonctionnalités les plus pertinentes. La sélection des caractéristiques pertinentes dans les sous-sections de l'image se fait soit en saisissant le nombre maximum, soit en faisant la moyenne des nombres dans cette région.\n",
        "\n",
        "Pour les tâches de classification d'images, il est plus courant d'utiliser des couches de pooling maximum que des couches de pooling moyennes. En effet, le premier a montré de meilleurs résultats dans les tâches où la préservation des caractéristiques les plus pertinentes est la clé, tandis que le second s'est avéré mieux fonctionner dans des tâches telles que le lissage d'images.\n",
        "\n",
        "pour calculer la forme de la matrice de sortie, utilisez l'équation suivante:\n",
        "\n",
        "$$ output\\ width = \\frac{ W - F}{S}+1$$\n",
        "\n",
        "Ici, $W$ fait référence à la largeur de l'entrée, $F$ à la taille du filtre et $S$ au stride. La même équation peut être adaptée pour calculer la hauteur de sortie.\n",
        "\n",
        "Les canaux ou la profondeur de l'entrée restent inchangés car la couche de pooling effectuera la même opération sur tous les canaux de l'image. Cela signifie que le résultat d'une couche de pooling n'affecte l'entrée qu'en termes de largeur et de longueur"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WcuFe0hF4vuT"
      },
      "source": [
        "### Exercice : Calcul de la forme de sortie d'un ensemble de couches convolutives et de pooling.\n",
        "\n",
        "L'exercice suivant combinera à la fois les couches convolutives et de pooling. L'objectif est de déterminer la taille de la matrice de sortie après avoir parcouru un ensemble de couches.\n",
        "\n",
        "Considérez les ensembles de calques suivants et spécifiez la forme du calque de sortie à la fin de toutes les transformations, en considérant une image d'entrée de taille 256 x 256 x 3\n",
        "\n",
        "* 1. Une couche convolutive avec 16 filtres de taille 3, et un stride et un padding de 1\n",
        "* 2. Une couche de pooling avec un filtre de taille deux et un stride de taille deux également.\n",
        "* 3. Une couche convolutive avec huit filtres de taille sept, un stride d'un et un padding de trois.\n",
        "* 4. Une couche de pooling avec un filtre de taille deux et un stride de deux également\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2DJ8nY6j5_-0"
      },
      "source": [
        "La taille de sortie de la matrice après avoir traversé chacune de ces couches est la suivante:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u07827yK8mQQ"
      },
      "source": [
        "* 1.  Après la première couche convolutive:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0nqzE_LZ6F1Y"
      },
      "source": [
        "output_width_height = ((256 - 3) + 2 * 1)/1 + 1\n",
        "output_channels = 16\n",
        "output_matrix_size = (256 , 256 , 16)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rd6vto_v6y7H"
      },
      "source": [
        "* 2. Après la première couche de pooling :\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBB34_Je620C"
      },
      "source": [
        "output_width_height = ((256 - 2) )/2 + 1\n",
        "output_channels = 16\n",
        "output_matrix_size = (128 , 128 , 16)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LT_YsJwv7Sal"
      },
      "source": [
        "* 3. Après la deuxième couche convolutive  :\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88SHDrOx7WKZ"
      },
      "source": [
        "output_width_height = ((128 - 7) + 2 * 3)/1 + 1\n",
        "output_channels = 8\n",
        "output_matrix_size = (128 , 128 , 8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvL1B3Wz78Lo"
      },
      "source": [
        "* 4. Après la deuxième couche de pooling :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "om1hpQlW790N"
      },
      "source": [
        "output_width_height = ((128 - 2))/2 + 1\n",
        "output_channels = 8\n",
        "output_matrix_size = (64 , 64 , 8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RzXXbBAI89Vd"
      },
      "source": [
        "En utilisant les mêmes exemples de codage que précédemment, la méthode PyTorch pour définir les couches de pooling est illustrée dans l'extrait de code suivant:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMlQeK7e9Ine"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class CNN_network(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(CNN_network, self).def__init__\n",
        "    self.conv1 = nn.Conv2d(3, 18, 3, 1,1)\n",
        "    self.pool1 = nn.MaxPool2d(2,2)\n",
        "    \n",
        "  def forward(self, x):\n",
        "    x = F.relu(self.conv1(x))\n",
        "    x = self.pool1(x)\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ml2dJco9hCJ"
      },
      "source": [
        "Comme on peut le voir, une couche de pooling (MaxPool2d) a été ajoutée à l'architecture réseau dans la méthode __init__. Ici, les arguments qui entrent dans les couches de pooling max, de gauche à droite, sont la taille du filtre (2) et le stride (2). Ensuite, la méthode forward a été mise à jour pour transmettre les informations à travers la nouvelle couche de pooling.\n",
        "\n",
        "Encore une fois, une approche tout aussi valable est illustrée ici, avec l'utilisation de modules personnalisés et de conteneurs séquentiels :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7Fodxzu90R5"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class CNN_network(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(CNN_network, self).def__init__\n",
        "    self.conv1 = nn.Sequential(nn.Conv2d(3, 18, 3, 1,1), nn.ReLU(), nn.MaxPool2d(2,2))\n",
        "    \n",
        "  def forward(self, x):\n",
        "    x = self.conv1(x)\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7RVkauBV-D8e"
      },
      "source": [
        "Comme nous l'avons mentionné précédemment, la couche de pooling est également incluse dans le même conteneur que la couche convolutive, en dessous de la fonction d'activation. Un ensemble ultérieur de couches (convolutionnelles, d'activation et de Pooling) serait défini ci-dessous, dans un nouveau conteneur séquentiel.\n",
        "Encore une fois, la méthode forward n'a plus besoin d'appeler chaque couche individuellement ; au lieu de cela, il transmet les informations à travers le conteneur, qui contient à la fois les couches et la fonction d'activation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pj63Ht7d--l3"
      },
      "source": [
        "###Couches entièrement connectées.\n",
        "\n",
        "La ou les couches FC sont définies à la fin de l'architecture du réseau après que l'entrée ait traversé un ensemble de couches convolutives et de pooling. Les données de sortie de la couche précédant sont aplaties d'une matrice dans un vecteur, qui peut être transmis à la couche FC (le même qu'une couche cachée des réseaux de neurones traditionnels).\n",
        "\n",
        "Le but principal de ces couches FC est de considérer toutes les caractéristiques qui ont été détectées par les couches précédentes, afin de classer l'image.\n",
        "\n",
        "Les différentes couches FC passent par une fonction d'activation, qui est typiquement la fonction ReLU, à moins que ce ne soit la couche finale, qui utilisera une fonction softmax pour sortir la probabilité de l'entrée appartenant à chacune des étiquettes de classe.\n",
        "\n",
        "La taille d'entrée de la première couche FC correspond à la taille de la matrice de sortie aplatie de la couche précédente. La taille de sortie est définie par l'utilisateur et, encore une fois, comme pour les ANN, il n'y a pas de science exacte pour définir ce nombre. La dernière couche FC doit avoir une taille de sortie égale au nombre d'étiquettes de classe.\n",
        "\n",
        "Pour définir un ensemble de couches FC dans PyTorch, considérez l'extrait de code suivant\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YkTGUm86AYL6"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class CNN_network(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(CNN_network, self).def__init__\n",
        "    self.conv1 = nn.Conv2d(3, 18, 3, 1,1)\n",
        "    self.pool1 = nn.MaxPool2d(2,2)\n",
        "    self.linear1 = nn.Linear(32*32*16, 64)\n",
        "    self.linear2 = nn.Linear(64, 10)\n",
        "    \n",
        "  def forward(self, x):\n",
        "    x = F.relu(self.conv1(x))\n",
        "    x = self.pool1(x)\n",
        "    x = x.view(-1, 32 * 32 *16)\n",
        "    x = F.relu(self.linear1(x))\n",
        "    x= F.log_softmax(self.linear2(x), dim=1)\n",
        "    return x"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WEgaBr5_BK1a"
      },
      "source": [
        "En utilisant le même exemple de codage que dans la section précédente, deux couches FC sont ajoutées au réseau à l'intérieur de la méthode __init__. Ensuite, à l'intérieur de la fonction forward, la sortie de la couche de pooling est aplatie à l'aide de la fonction view(). Ensuite, il est passé à travers la première couche FC, qui applique une fonction d'activation. Enfin, les données sont passées à travers une couche finale FC, ainsi que sa fonction d'activation.\n",
        "\n",
        "Encore une fois, en utilisant le même exemple de codage que précédemment, il est possible d'ajouter des couches FC à notre modèle en utilisant à la fois des modules personnalisés et le conteneur Sequential, comme suit :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVZbem54BlFs"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class CNN_network(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(CNN_network, self).def__init__\n",
        "    self.conv1 = nn.Sequential(nn.Conv2d(1, 16, 5, 1, 2,),                                  \n",
        "                               nn.ReLU(),\n",
        "                               nn.MaxPool2d(2, 2))\n",
        "    self.linear1 = nn.Linear(32*32*16, 64)        \n",
        "    self.linear2 = nn.Linear(64, 10)\n",
        "    \n",
        "  def forward(self, x):\n",
        "    x = self.conv1(x)        \n",
        "    x = x.view(-1, 32 * 32 *16)        \n",
        "    x = F.relu(self.linear1(x))        \n",
        "    x = F.log_softmax(self.linear2(x), dim=1)\n",
        "    return x"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZw23lK8CE5m"
      },
      "source": [
        "Comme on peut le voir, le conteneur Sequential est laissé intact et les deux couches FC sont ajoutées en dessous, à l'intérieur de la méthode __init__. Ensuite, la fonction forward transmet les informations à travers l'ensemble du conteneur, pour ensuite aplatir la sortie à transmettre à travers les couches FC.\n",
        "\n",
        "Une fois l'architecture du réseau définie, les étapes suivantes pour la formation du réseau peuvent être traitées de la même manière que pour les ANN."
      ]
    }
  ]
}